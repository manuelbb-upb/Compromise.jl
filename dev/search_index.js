var documenterSearchIndex = {"docs":
[{"location":"mop/#AbstractMOP-Interface","page":"AbstractMOP Interface","title":"AbstractMOP Interface","text":"","category":"section"},{"location":"mop/","page":"AbstractMOP Interface","title":"AbstractMOP Interface","text":"An object subtyping AbstractMOP is a glorified wrapper around vector-vector functions. The methods below were originally meant to be used to implement our algorithm similar to how it has been stated in the article, rather “mathematically“. That is, we do not care for how the problem has been modelled and set up. We only need function handles and some meta-data concerning dimensions and data types.","category":"page"},{"location":"mop/","page":"AbstractMOP Interface","title":"AbstractMOP Interface","text":"Formally, our problem reads","category":"page"},{"location":"mop/","page":"AbstractMOP Interface","title":"AbstractMOP Interface","text":"beginaligned\nmin_x = x₁  x_N\n    beginbmatrix\n        f₁(x)   \n               \n        f_K(x)\n    endbmatrix\n        textsubject to\n     g(x) = g₁(x)  g_P(x)  0 \n     h(x) = h₁(x)  h_M(x) = 0 \n     lb  x  ub  A  x  b E  x = c\nendaligned","category":"page"},{"location":"mop/","page":"AbstractMOP Interface","title":"AbstractMOP Interface","text":"In the code, we often follow this notation:","category":"page"},{"location":"mop/","page":"AbstractMOP Interface","title":"AbstractMOP Interface","text":"f indicates an objective function.\ng a nonlinear inequality constraint.\nh a nonlinear equality constriant.\nA is the matrix of linear inequality constraints, b the right hand side vector.\nE is the matrix of linear equality constraints, c the right hand side vector.\nlb and ub define box constraints.","category":"page"},{"location":"mop/","page":"AbstractMOP Interface","title":"AbstractMOP Interface","text":"At the beginning of an optimization routine, initialization based on the initial site can be performed:","category":"page"},{"location":"mop/","page":"AbstractMOP Interface","title":"AbstractMOP Interface","text":"initialize(mop::AbstractMOP, ξ0::RVec)=mop","category":"page"},{"location":"mop/#Meta-Data","page":"AbstractMOP Interface","title":"Meta-Data","text":"","category":"section"},{"location":"mop/","page":"AbstractMOP Interface","title":"AbstractMOP Interface","text":"The optional function precision returns the type of result and derivative vectors:","category":"page"},{"location":"mop/","page":"AbstractMOP Interface","title":"AbstractMOP Interface","text":"precision(::AbstractMOP)::Type{<:AbstractFloat}=DEFAULT_PRECISION","category":"page"},{"location":"mop/","page":"AbstractMOP Interface","title":"AbstractMOP Interface","text":"We would also like to deterministically query the expected surrogate model types:","category":"page"},{"location":"mop/","page":"AbstractMOP Interface","title":"AbstractMOP Interface","text":"model_type(::AbstractMOP)::Type{<:AbstractMOPSurrogate}=AbstractMOPSurrogate","category":"page"},{"location":"mop/","page":"AbstractMOP Interface","title":"AbstractMOP Interface","text":"Below functions are used to query dimension information.","category":"page"},{"location":"mop/","page":"AbstractMOP Interface","title":"AbstractMOP Interface","text":"dim_objectives(::AbstractMOP)::Int=0            # mandatory\ndim_nl_eq_constraints(::AbstractMOP)::Int=0     # optional\ndim_nl_ineq_constraints(::AbstractMOP)::Int=0   # optional","category":"page"},{"location":"mop/#Linear-Constraints","page":"AbstractMOP Interface","title":"Linear Constraints","text":"","category":"section"},{"location":"mop/","page":"AbstractMOP Interface","title":"AbstractMOP Interface","text":"An AbstractMOP can have constrained variables. The corresponding functions should return full bound vectors or nothing. For lower bounds, nothing corresponds to -Inf, but we do not necessarily use such vectors in the inner solver. Upper bounds would be Inf in case of nothing.","category":"page"},{"location":"mop/","page":"AbstractMOP Interface","title":"AbstractMOP Interface","text":"lower_var_bounds(::AbstractMOP)::Union{Nothing, Vec}=nothing\nupper_var_bounds(::AbstractMOP)::Union{Nothing, Vec}=nothing","category":"page"},{"location":"mop/","page":"AbstractMOP Interface","title":"AbstractMOP Interface","text":"Moreover, problems can have linear equality constraints and linear inequality constraints","category":"page"},{"location":"mop/","page":"AbstractMOP Interface","title":"AbstractMOP Interface","text":"  E x = c\n  quad\n  A x  b","category":"page"},{"location":"mop/","page":"AbstractMOP Interface","title":"AbstractMOP Interface","text":"lin_eq_constraints(::AbstractMOP)::Union{Nothing, Tuple{RMat,RVecOrMat}}=nothing\nlin_ineq_constraints(::AbstractMOP)::Union{Nothing, Tuple{RMat,RVecOrMat}}=nothing","category":"page"},{"location":"mop/","page":"AbstractMOP Interface","title":"AbstractMOP Interface","text":"From that we can derive dimension getters as well:","category":"page"},{"location":"mop/","page":"AbstractMOP Interface","title":"AbstractMOP Interface","text":"# helper\ndim_lin_constraints(dat::Nothing)=0\nfunction dim_lin_constraints((A,b)::Tuple{RMat, RVecOrMat})\n    dim = length(b)\n    @assert size(A, 2) == dim \"Dimension mismatch in linear constraints.\"\n    return dim\nend\n# actual functions\ndim_lin_eq_constraints(mop::AbstractMOP)=dim_lin_constraints(lin_eq_constraints(mop))\ndim_lin_ineq_constraints(mop::AbstractMOP)=dim_lin_constraints(lin_ineq_constraints(mop))","category":"page"},{"location":"mop/#Evaluation","page":"AbstractMOP Interface","title":"Evaluation","text":"","category":"section"},{"location":"mop/","page":"AbstractMOP Interface","title":"AbstractMOP Interface","text":"note: Note\nAll evaluation and differentiation methods that you see below should always return nothing, unless you want to stop early. Then return something else, for example a string.","category":"page"},{"location":"mop/","page":"AbstractMOP Interface","title":"AbstractMOP Interface","text":"Evaluation of nonlinear objective functions requires the following method:","category":"page"},{"location":"mop/","page":"AbstractMOP Interface","title":"AbstractMOP Interface","text":"function eval_objectives!(y::RVec, mop::M, x::RVec) where {M<:AbstractMOP}\n    error(\"`eval_objectives!(y, mop, x) not implemented for mop of type $(M).\")\nend","category":"page"},{"location":"mop/","page":"AbstractMOP Interface","title":"AbstractMOP Interface","text":"If there are constraints, these have to be defined as well:","category":"page"},{"location":"mop/","page":"AbstractMOP Interface","title":"AbstractMOP Interface","text":"function eval_nl_eq_constraints!(y::RVec, mop::M, x::RVec) where {M<:AbstractMOP}\n    error(\"`eval_nl_eq_constraints!(y, mop, x) not implemented for mop of type $(M).\")\nend\nfunction eval_nl_ineq_constraints!(y::RVec, mop::M, x::RVec) where {M<:AbstractMOP}\n    error(\"`eval_nl_ineq_constraints!(y, mop, x) not implemented for mop of type $(M).\")\nend","category":"page"},{"location":"mop/","page":"AbstractMOP Interface","title":"AbstractMOP Interface","text":"To ensure, they only get called if needed, we wrap them and assign shorter names:","category":"page"},{"location":"mop/","page":"AbstractMOP Interface","title":"AbstractMOP Interface","text":"objectives!(y::RVec, mop::AbstractMOP, x::RVec)=eval_objectives!(y, mop, x)\nnl_eq_constraints!(y::Nothing, mop::AbstractMOP, x::RVec)=nothing\nnl_ineq_constraints!(y::Nothing, mop::AbstractMOP, x::RVec)=nothing\nnl_eq_constraints!(y::RVec, mop::AbstractMOP, x::RVec)=eval_nl_eq_constraints!(y, mop, x)\nnl_ineq_constraints!(y::RVec, mop::AbstractMOP, x::RVec)=eval_nl_ineq_constraints!(y, mop, x)","category":"page"},{"location":"mop/","page":"AbstractMOP Interface","title":"AbstractMOP Interface","text":"Similar methods can be defined for linear constraints.","category":"page"},{"location":"mop/","page":"AbstractMOP Interface","title":"AbstractMOP Interface","text":"\"\"\"\n    lin_cons!(residual_vector, prod_cache, constraint_data, x)\n\nGiven a linear constraint `A*x .<= b` or `A*x .== b`, compute the product `A*x` and store\nthe result in `prod_cache`, and also compute `A*x .- b` and store the result in\n`residual_vector`.\n`constraint_data` should either be the tuple `(A,b)::Tuple{RMat,RVec}` or `nothing`.\n\"\"\"\nlin_cons!(residual_vector, prod_cache, constraint_data, x)=nothing\nlin_cons!(res::Nothing, mat_vec::Nothing, cons::Nothing, x::RVec) = nothing\nfunction lin_cons!(res::RVec, mat_vec::RVec, (A, b)::Tuple, x::RVec)\n    LA.mul!(mat_vec, A, x)\n    @. res = mat_vec - b\n    return nothing\nend","category":"page"},{"location":"mop/","page":"AbstractMOP Interface","title":"AbstractMOP Interface","text":"More specific methods with descriptive names applicable to an AbstractMOP:","category":"page"},{"location":"mop/","page":"AbstractMOP Interface","title":"AbstractMOP Interface","text":"lin_eq_constraints!(res::Nothing, mat_vec::Nothing, mop::AbstractMOP, x::RVec)=nothing\nlin_ineq_constraints!(res::Nothing, mat_vec::Nothing, mop::AbstractMOP, x::RVec)=nothing\nlin_eq_constraints!(res::RVec, mat_vec::Nothing, mop::AbstractMOP, x::RVec)=lin_cons!(res, mat_vec, lin_eq_constraints(mop), x)\nlin_ineq_constraints!(res::RVec, mat_vec::Nothing, mop::AbstractMOP, x::RVec)=lin_cons!(res, mat_vec, lin_ineq_constraints(mop), x)","category":"page"},{"location":"mop/#Pre-Allocation","page":"AbstractMOP Interface","title":"Pre-Allocation","text":"","category":"section"},{"location":"mop/","page":"AbstractMOP Interface","title":"AbstractMOP Interface","text":"Why do we also allow nothing as the target for constraints? Because that is the default cache returned if there are none:","category":"page"},{"location":"mop/","page":"AbstractMOP Interface","title":"AbstractMOP Interface","text":"function prealloc_objectives_vector(mop::AbstractMOP)\n    T = precision(mop)\n    return Vector{T}(undef, dim_objectives(mop))\nend\n# hx = nonlinear equality constraints at x\n# gx = nonlinear inequality constraints at x\n# Ex = linear equality constraints at x\n# Ax = linear inequality constraints at x\n# These are defined below (and I put un-specific definitions here for the Linter)\nfunction prealloc_nl_eq_constraints_vector(mop) end\nfunction prealloc_nl_ineq_constraints_vector(mop) end\nfunction prealloc_lin_eq_constraints_vector(mop) end\nfunction prealloc_lin_ineq_constraints_vector(mop) end\nfor (dim_func, prealloc_func) in (\n    (:dim_nl_eq_constraints, :prealloc_nl_eq_constraints_vector),\n    (:dim_nl_ineq_constraints, :prealloc_nl_ineq_constraints_vector),\n    (:dim_lin_eq_constraints, :prealloc_lin_eq_constraints_vector),\n    (:dim_lin_ineq_constraints, :prealloc_lin_ineq_constraints_vector),\n)\n    @eval function $(prealloc_func)(mop::AbstractMOP)\n        dim = $(dim_func)(mop)\n        if dim > 0\n            T = precision(mop)\n            return Vector{T}(undef, dim)\n        else\n            return nothing\n        end\n    end\nend","category":"page"},{"location":"mop/","page":"AbstractMOP Interface","title":"AbstractMOP Interface","text":"","category":"page"},{"location":"mop/","page":"AbstractMOP Interface","title":"AbstractMOP Interface","text":"This page was generated using Literate.jl.","category":"page"},{"location":"models/#AbstractMOPSurrogate-Interface","page":"AbstractMOPSurrogate Interface","title":"AbstractMOPSurrogate Interface","text":"","category":"section"},{"location":"models/","page":"AbstractMOPSurrogate Interface","title":"AbstractMOPSurrogate Interface","text":"The speciality of our algorithm is its use of local surrogate models. These should subtype and implement AbstractMOPSurrogate. Every nonlinear function can be modelled, but we leave it to the implementation of an AbstractMOP, how exactly that is done.","category":"page"},{"location":"models/#Meta-Data","page":"AbstractMOPSurrogate Interface","title":"Meta-Data","text":"","category":"section"},{"location":"models/","page":"AbstractMOPSurrogate Interface","title":"AbstractMOPSurrogate Interface","text":"For convenience, we'd like to have the same meta information available as for the original MOP:","category":"page"},{"location":"models/","page":"AbstractMOPSurrogate Interface","title":"AbstractMOPSurrogate Interface","text":"precision(::AbstractMOPSurrogate)::Type{<:AbstractFloat}=DEFAULT_PRECISION\ndim_objectives(::AbstractMOPSurrogate)::Int=0            # mandatory\ndim_nl_eq_constraints(::AbstractMOPSurrogate)::Int=0     # optional\ndim_nl_ineq_constraints(::AbstractMOPSurrogate)::Int=0   # optional","category":"page"},{"location":"models/","page":"AbstractMOPSurrogate Interface","title":"AbstractMOPSurrogate Interface","text":"Additionally, we require information on the model variability and if we can build models for the scaled domain:","category":"page"},{"location":"models/","page":"AbstractMOPSurrogate Interface","title":"AbstractMOPSurrogate Interface","text":"depends_on_radius(::AbstractMOPSurrogate)::Bool=true\nsupports_scaling(T::Type{<:AbstractMOPSurrogate})=NoScaling()","category":"page"},{"location":"models/#Construction","page":"AbstractMOPSurrogate Interface","title":"Construction","text":"","category":"section"},{"location":"models/","page":"AbstractMOPSurrogate Interface","title":"AbstractMOPSurrogate Interface","text":"Define a function to return a model for some MOP. The model does not yet have to be trained.","category":"page"},{"location":"models/","page":"AbstractMOPSurrogate Interface","title":"AbstractMOPSurrogate Interface","text":"init_models(mop::AbstractMOP, n_vars, scaler)::AbstractMOPSurrogate=nothing","category":"page"},{"location":"models/","page":"AbstractMOPSurrogate Interface","title":"AbstractMOPSurrogate Interface","text":"It is trained with the update method update_models!.","category":"page"},{"location":"models/","page":"AbstractMOPSurrogate Interface","title":"AbstractMOPSurrogate Interface","text":"note: Note\nThis method should always return nothing, unless you want to stop the algorithm. Every other return value stops the algoritm and  GenericStopping(ret_val) is returned as the stop code. The constructor of GenericStopping logs the ret_val, so you could return a string explaining the reason for stopping.","category":"page"},{"location":"models/","page":"AbstractMOPSurrogate Interface","title":"AbstractMOPSurrogate Interface","text":"function update_models!(\n    mod::AbstractMOPSurrogate, Δ, mop, scaler, vals, scaled_cons, algo_opts\n)\n    return nothing\nend","category":"page"},{"location":"models/","page":"AbstractMOPSurrogate Interface","title":"AbstractMOPSurrogate Interface","text":"If a model is radius-dependent, we also need a function to copy the parameters from a source model to a target model:","category":"page"},{"location":"models/","page":"AbstractMOPSurrogate Interface","title":"AbstractMOPSurrogate Interface","text":"copy_model(mod::AbstractMOPSurrogate)=deepcopy(mod)\ncopyto_model!(mod_trgt::AbstractMOPSurrogate, mod_src::AbstractMOPSurrogate)=mod_trgt","category":"page"},{"location":"models/","page":"AbstractMOPSurrogate Interface","title":"AbstractMOPSurrogate Interface","text":"These internal helpers are derived:","category":"page"},{"location":"models/","page":"AbstractMOPSurrogate Interface","title":"AbstractMOPSurrogate Interface","text":"_copy_model(mod::AbstractMOPSurrogate)=depends_on_radius(mod) ? copy_model(mod) : mod\n_copyto_model!(mod_trgt::AbstractMOPSurrogate, mod_src::AbstractMOPSurrogate)=depends_on_radius(mod_trgt) ? copyto_model!(mod_trgt, mod_src) : mod_trgt","category":"page"},{"location":"models/#Evaluation","page":"AbstractMOPSurrogate Interface","title":"Evaluation","text":"","category":"section"},{"location":"models/","page":"AbstractMOPSurrogate Interface","title":"AbstractMOPSurrogate Interface","text":"note: Note\nAll evaluation and differentiation methods that you see below should always return nothing, unless you want to stop early. Then return something else, for example a string.","category":"page"},{"location":"models/","page":"AbstractMOPSurrogate Interface","title":"AbstractMOPSurrogate Interface","text":"Evaluation of nonlinear objective models requires the following method. x will be from the scaled domain, but if a model does not support scaling, then internally the IdentityScaler() is used:","category":"page"},{"location":"models/","page":"AbstractMOPSurrogate Interface","title":"AbstractMOPSurrogate Interface","text":"function eval_objectives!(y::RVec, mod::M, x::RVec) where {M<:AbstractMOPSurrogate}\n    error(\"`eval_objectives!(y, mod, x) not implemented for mod of type $(M).\")\nend","category":"page"},{"location":"models/","page":"AbstractMOPSurrogate Interface","title":"AbstractMOPSurrogate Interface","text":"If there are constraints, these have to be defined as well:","category":"page"},{"location":"models/","page":"AbstractMOPSurrogate Interface","title":"AbstractMOPSurrogate Interface","text":"function eval_nl_eq_constraints!(y::RVec, mod::M, x::RVec) where {M<:AbstractMOPSurrogate}\n    error(\"`eval_nl_eq_constraints!(y, mod, x) not implemented for mod of type $(M).\")\nend\nfunction eval_nl_ineq_constraints!(y::RVec, mod::M, x::RVec) where {M<:AbstractMOPSurrogate}\n    error(\"`eval_nl_ineq_constraints!(y, mod, x) not implemented for mod of type $(M).\")\nend","category":"page"},{"location":"models/","page":"AbstractMOPSurrogate Interface","title":"AbstractMOPSurrogate Interface","text":"As before, we use shorter function names in the algorithm.","category":"page"},{"location":"models/","page":"AbstractMOPSurrogate Interface","title":"AbstractMOPSurrogate Interface","text":"objectives!(y::RVec, mod::AbstractMOPSurrogate, x::RVec)=eval_objectives!(y, mod, x)\nnl_eq_constraints!(y::Nothing, mod::AbstractMOPSurrogate, x::RVec)=nothing\nnl_ineq_constraints!(y::Nothing, mod::AbstractMOPSurrogate, x::RVec)=nothing\nnl_eq_constraints!(y::RVec, mod::AbstractMOPSurrogate, x::RVec)=eval_nl_eq_constraints!(y, mod, x)\nnl_ineq_constraints!(y::RVec, mod::AbstractMOPSurrogate, x::RVec)=eval_nl_ineq_constraints!(y, mod, x)","category":"page"},{"location":"models/#Pre-Allocation","page":"AbstractMOPSurrogate Interface","title":"Pre-Allocation","text":"","category":"section"},{"location":"models/","page":"AbstractMOPSurrogate Interface","title":"AbstractMOPSurrogate Interface","text":"The preallocation functions look the same as for AbstractMOP:","category":"page"},{"location":"models/","page":"AbstractMOPSurrogate Interface","title":"AbstractMOPSurrogate Interface","text":"for (dim_func, prealloc_func) in (\n    (:dim_objectives, :prealloc_objectives_vector),\n    (:dim_nl_eq_constraints, :prealloc_nl_eq_constraints_vector),\n    (:dim_nl_ineq_constraints, :prealloc_nl_ineq_constraints_vector),\n)\n    @eval function $(prealloc_func)(mod::AbstractMOPSurrogate)\n        dim = $(dim_func)(mod)\n        if dim > 0\n            T = precision(mod)\n            return Vector{T}(undef, dim)\n        else\n            return nothing\n        end\n    end\nend","category":"page"},{"location":"models/#Differentiation","page":"AbstractMOPSurrogate Interface","title":"Differentiation","text":"","category":"section"},{"location":"models/","page":"AbstractMOPSurrogate Interface","title":"AbstractMOPSurrogate Interface","text":"The surrogate models are also used to query approximate derivative information. We hence need the following functions to make Dy transposed model Jacobians:","category":"page"},{"location":"models/","page":"AbstractMOPSurrogate Interface","title":"AbstractMOPSurrogate Interface","text":"function grads_objectives!(Dy::RMat, mod::M, x::RVec) where {M<:AbstractMOPSurrogate}\n    error(\"`grads_objectives!(Dy, mod, x) not implemented for mod of type $(M).\")\nend","category":"page"},{"location":"models/","page":"AbstractMOPSurrogate Interface","title":"AbstractMOPSurrogate Interface","text":"If there are constraints, these have to be defined as well:","category":"page"},{"location":"models/","page":"AbstractMOPSurrogate Interface","title":"AbstractMOPSurrogate Interface","text":"function grads_nl_eq_constraints!(Dy::RMat, mod::M, x::RVec) where {M<:AbstractMOPSurrogate}\n    error(\"`grads_nl_eq_constraints!(Dy, mod, x) not implemented for mod of type $(M).\")\nend\nfunction grads_nl_ineq_constraints!(Dy::RMat, mod::M, x::RVec) where {M<:AbstractMOPSurrogate}\n    error(\"`grads_nl_ineq_constraints!(Dy, mod, x) not implemented for mod of type $(M).\")\nend","category":"page"},{"location":"models/","page":"AbstractMOPSurrogate Interface","title":"AbstractMOPSurrogate Interface","text":"Here, the names of the wrapper functions start with “diff“.","category":"page"},{"location":"models/","page":"AbstractMOPSurrogate Interface","title":"AbstractMOPSurrogate Interface","text":"diff_objectives!(Dy::RMat, mod::AbstractMOPSurrogate, x::RVec)=grads_objectives!(Dy, mod, x)\ndiff_nl_eq_constraints!(Dy::Nothing, mod::AbstractMOPSurrogate, x::RVec)=nothing\ndiff_nl_ineq_constraints!(Dy::Nothing, mod::AbstractMOPSurrogate, x::RVec)=nothing\ndiff_nl_eq_constraints!(Dy::RMat, mod::AbstractMOPSurrogate, x::RVec)=grads_nl_eq_constraints!(Dy, mod, x)\ndiff_nl_ineq_constraints!(Dy::RMat, mod::AbstractMOPSurrogate, x::RVec)=grads_nl_ineq_constraints!(Dy, mod, x)","category":"page"},{"location":"models/","page":"AbstractMOPSurrogate Interface","title":"AbstractMOPSurrogate Interface","text":"Optionally, we can have evaluation and differentiation in one go:","category":"page"},{"location":"models/","page":"AbstractMOPSurrogate Interface","title":"AbstractMOPSurrogate Interface","text":"function eval_and_grads_objectives!(y::RVec, Dy::RMat, mod::M, x::RVec) where {M<:AbstractMOPSurrogate}\n    eval_objectives!(y, mop, x)\n    grads_objectives!(Dy, mod, x)\n    return nothing\nend\nfunction eval_grads_nl_eq_constraints!(y::RVec, Dy::RMat, mod::M, x::RVec) where {M<:AbstractMOPSurrogate}\n    eval_nl_eq_constraints!(y, mop, x)\n    grads_nl_eq_constraints!(Dy, mod, x)\n    return nothing\nend\nfunction eval_grads_nl_ineq_constraints!(y::RVec, Dy::RMat, mod::M, x::RVec) where {M<:AbstractMOPSurrogate}\n    eval_nl_ineq_constraints!(y, mop, x)\n    grads_nl_ineq_constraints!(Dy, mod, x)\n    return nothing\nend","category":"page"},{"location":"models/","page":"AbstractMOPSurrogate Interface","title":"AbstractMOPSurrogate Interface","text":"Wrappers for use in the algorithm:","category":"page"},{"location":"models/","page":"AbstractMOPSurrogate Interface","title":"AbstractMOPSurrogate Interface","text":"vals_diff_objectives!(y::RVec, Dy::RMat, mod::AbstractMOPSurrogate, x::RVec)=eval_and_grads_objectives!(y, Dy, mod, x)\nvals_diff_nl_eq_constraints!(y::Nothing, Dy::Nothing, mod::AbstractMOPSurrogate, x::RVec)=nothing\nvals_diff_nl_ineq_constraints!(y::Nothing, Dy::Nothing, mod::AbstractMOPSurrogate, x::RVec)=nothing\nvals_diff_nl_eq_constraints!(y::RVec, Dy::RMat, mod::AbstractMOPSurrogate, x::RVec)=eval_and_grads_nl_eq_constraints!(y, Dy, mod, x)\nvals_diff_nl_ineq_constraints!(y::RVec, Dy::RMat, mod::AbstractMOPSurrogate, x::RVec)=eval_and_grads_nl_ineq_constraints!(y, Dy, mod, x)","category":"page"},{"location":"models/","page":"AbstractMOPSurrogate Interface","title":"AbstractMOPSurrogate Interface","text":"Here is what is called later on:","category":"page"},{"location":"models/","page":"AbstractMOPSurrogate Interface","title":"AbstractMOPSurrogate Interface","text":"\"Evaluate the models `mod` at `x` and store results in `mod_vals::SurrogateValueArrays`.\"\nfunction eval_mod!(mod_vals, mod, x)\n    @unpack fx, hx, gx = mod_vals\n    @serve objectives!(fx, mod, x)\n    @serve nl_eq_constraints!(hx, mod, x)\n    @serve nl_ineq_constraints!(hx, mod, x)\n    return nothing\nend\n\n\"Evaluate the model gradients of `mod` at `x` and store results in `mod_vals::SurrogateValueArrays`.\"\nfunction diff_mod!(mod_vals, mod, x)\n    @unpack Dfx, Dhx, Dgx = mod_vals\n    @serve diff_objectives!(Dfx, mod, x)\n    @serve diff_nl_eq_constraints!(Dhx, mod, x)\n    @serve diff_nl_ineq_constraints!(hx, mod, x)\n    return nothing\nend\n\n\"Evaluate and differentiate `mod` at `x` and store results in `mod_vals::SurrogateValueArrays`.\"\nfunction eval_and_diff_mod!(mod_vals, mod, x)\n    @unpack fx, hx, gx, Dfx, Dhx, Dgx = mod_vals\n    @serve vals_diff_objectives!(fx, Dfx, mod, x)\n    @serve vals_diff_nl_eq_constraints!(hx, Dhx, mod, x)\n    @serve vals_diff_nl_ineq_constraints!(gx, Dgx, mod, x)\n    return nothing\nend","category":"page"},{"location":"models/#Gradient-Pre-Allocation","page":"AbstractMOPSurrogate Interface","title":"Gradient Pre-Allocation","text":"","category":"section"},{"location":"models/","page":"AbstractMOPSurrogate Interface","title":"AbstractMOPSurrogate Interface","text":"We also would like to have pre-allocated gradient arrays ready:","category":"page"},{"location":"models/","page":"AbstractMOPSurrogate Interface","title":"AbstractMOPSurrogate Interface","text":"function prealloc_objectives_grads(mod::AbstractMOPSurrogate, n_vars)\n    T = precision(mod)\n    return Matrix{T}(undef, n_vars, dim_objectives(mod))\nend\n# These are defined below (and I put un-specific definitions here for the Linter)\nfunction prealloc_nl_eq_constraints_grads(mod, n_vars) end\nfunction prealloc_nl_ineq_constraints_grads(mod, n_vars) end\nfor (dim_func, prealloc_func) in (\n    (:dim_nl_eq_constraints, :prealloc_nl_eq_constraints_grads),\n    (:dim_nl_ineq_constraints, :prealloc_nl_ineq_constraints_grads),\n)\n    @eval function $(prealloc_func)(mod::AbstractMOPSurrogate, n_vars)\n        n_out = $(dim_func)(mod)\n        if n_out > 0\n            T = precision(mod)\n            return Matrix{T}(undef, n_vars, n_out)\n        else\n            return nothing\n        end\n    end\nend","category":"page"},{"location":"models/","page":"AbstractMOPSurrogate Interface","title":"AbstractMOPSurrogate Interface","text":"note: Note\nFor nonlinear subproblem solvers it might be desirable to have partial evaluation and differentiation functions. Also, out-of-place functions could be useful for external nonlinear tools, but I don't need them yet. Defining the latter methods would simply call prealloc_XXX first and then use some in-place-functions.","category":"page"},{"location":"models/","page":"AbstractMOPSurrogate Interface","title":"AbstractMOPSurrogate Interface","text":"","category":"page"},{"location":"models/","page":"AbstractMOPSurrogate Interface","title":"AbstractMOPSurrogate Interface","text":"This page was generated using Literate.jl.","category":"page"},{"location":"CompromiseEvaluators/#Module-CompromiseEvaluators","page":"Module CompromiseEvaluators","title":"Module CompromiseEvaluators","text":"","category":"section"},{"location":"CompromiseEvaluators/","page":"Module CompromiseEvaluators","title":"Module CompromiseEvaluators","text":"This file provides a submodule defining abstract types and interfaces for evaluation of vector-vector-functions and surrogate models.","category":"page"},{"location":"CompromiseEvaluators/#AbstractNonlinearOperator-Interface","page":"Module CompromiseEvaluators","title":"AbstractNonlinearOperator Interface","text":"","category":"section"},{"location":"CompromiseEvaluators/","page":"Module CompromiseEvaluators","title":"Module CompromiseEvaluators","text":"An object subtyping AbstractNonlinearOperator represents a function mapping real-valued vectors to real-valued vectors. The interface defines methods to evaluate such a function. These methods are used internally by Compromise, and we made the decision to assume in-place functions. If the user has out-of-place functions, they have to transform them accordingly. Alternatively, this functionality can be provided by utility types implementing the interface.","category":"page"},{"location":"CompromiseEvaluators/","page":"Module CompromiseEvaluators","title":"Module CompromiseEvaluators","text":"abstract type AbstractNonlinearOperator end","category":"page"},{"location":"CompromiseEvaluators/","page":"Module CompromiseEvaluators","title":"Module CompromiseEvaluators","text":"A function can have parameters that are constant in a single optimization run, and the type structure reflects this distinction:","category":"page"},{"location":"CompromiseEvaluators/","page":"Module CompromiseEvaluators","title":"Module CompromiseEvaluators","text":"abstract type AbstractNonlinearOperatorWithParams <: AbstractNonlinearOperator end\nabstract type AbstractNonlinearOperatorNoParams <: AbstractNonlinearOperator end","category":"page"},{"location":"CompromiseEvaluators/#Common-Methods","page":"Module CompromiseEvaluators","title":"Common Methods","text":"","category":"section"},{"location":"CompromiseEvaluators/","page":"Module CompromiseEvaluators","title":"Module CompromiseEvaluators","text":"Both, AbstractNonlinearOperatorWithParams and AbstractNonlinearOperatorNoParams have methods like eval_op!. The signatures look different, though. That is why there is a separate section for both types. The below methods have the same signature for both operator supertypes:","category":"page"},{"location":"CompromiseEvaluators/","page":"Module CompromiseEvaluators","title":"Module CompromiseEvaluators","text":"Evaluation of derivatives is optional if evaluation-based models are used. We have functions to indicate if an operator implements eval_grads!, eval_hessians!:","category":"page"},{"location":"CompromiseEvaluators/","page":"Module CompromiseEvaluators","title":"Module CompromiseEvaluators","text":"provides_grads(op::AbstractNonlinearOperator)=false\nprovides_hessians(op::AbstractNonlinearOperator)=false","category":"page"},{"location":"CompromiseEvaluators/","page":"Module CompromiseEvaluators","title":"Module CompromiseEvaluators","text":"In certain situations (nonlinear subproblems relying on minimization of scalar-valued objective or constraint compoments) it might be beneficial if only certain outputs of a vector-function could be evaluated. The method supports_partial_evaluation signals this feature. If it returns true, the feature is assumed to be available for derivatives as well. In this situation, the type should implment methods starting with partial_, see below for details.","category":"page"},{"location":"CompromiseEvaluators/","page":"Module CompromiseEvaluators","title":"Module CompromiseEvaluators","text":"supports_partial_evaluation(op::AbstractNonlinearOperator) = false","category":"page"},{"location":"CompromiseEvaluators/","page":"Module CompromiseEvaluators","title":"Module CompromiseEvaluators","text":"Stopping based on the number of evaluations is surprisingly hard if we don't want to give up most of the flexibility and composability of Operators and(/in) Problems and models. To implement such a stopping mechanism, we would like the operator to count the number of evaluations.","category":"page"},{"location":"CompromiseEvaluators/","page":"Module CompromiseEvaluators","title":"Module CompromiseEvaluators","text":"is_counted(op::AbstractNonlinearOperator)=false","category":"page"},{"location":"CompromiseEvaluators/","page":"Module CompromiseEvaluators","title":"Module CompromiseEvaluators","text":"If is_counted returns true, we assume that we can safely call num_calls and get a 3-tuple of values: the number of function evaluations, gradient evaluations and Hessian evaluations:","category":"page"},{"location":"CompromiseEvaluators/","page":"Module CompromiseEvaluators","title":"Module CompromiseEvaluators","text":"num_calls(op::AbstractNonlinearOperator)::Tuple{Int, Int, Int}=nothing","category":"page"},{"location":"CompromiseEvaluators/","page":"Module CompromiseEvaluators","title":"Module CompromiseEvaluators","text":"In addition, there should be a method to (re-)set the counters:","category":"page"},{"location":"CompromiseEvaluators/","page":"Module CompromiseEvaluators","title":"Module CompromiseEvaluators","text":"set_num_calls!(op::AbstractNonlinearOperator,vals::Tuple{Int,Int,Int})=nothing","category":"page"},{"location":"CompromiseEvaluators/","page":"Module CompromiseEvaluators","title":"Module CompromiseEvaluators","text":"Stopping based on the number of evaluations is so fundamental, I make it part of the interface:","category":"page"},{"location":"CompromiseEvaluators/","page":"Module CompromiseEvaluators","title":"Module CompromiseEvaluators","text":"max_calls(op::AbstractNonlinearOperator)::Union{Nothing,NTuple{3, Union{Int,Nothing}}}=nothing","category":"page"},{"location":"CompromiseEvaluators/","page":"Module CompromiseEvaluators","title":"Module CompromiseEvaluators","text":"If you have enforce_max_calls return true, then we automatically check the number of evaluations (or differentiation calls). You then don't have to implement this yourself in eval_op! etc.","category":"page"},{"location":"CompromiseEvaluators/","page":"Module CompromiseEvaluators","title":"Module CompromiseEvaluators","text":"enforce_max_calls(op::AbstractNonlinearOperator)=true","category":"page"},{"location":"CompromiseEvaluators/","page":"Module CompromiseEvaluators","title":"Module CompromiseEvaluators","text":"note: Note\nWhether or not max_calls is respected depends on the implementation of AbstractMOPSurrogate or the implementation of update! for AbstractSurrogateModel...","category":"page"},{"location":"CompromiseEvaluators/#Methods-for-AbstractNonlinearOperatorWithParams","page":"Module CompromiseEvaluators","title":"Methods for AbstractNonlinearOperatorWithParams","text":"","category":"section"},{"location":"CompromiseEvaluators/","page":"Module CompromiseEvaluators","title":"Module CompromiseEvaluators","text":"note: Note\nThe evaluation methods should respect is_counted and internally increase any counters.","category":"page"},{"location":"CompromiseEvaluators/","page":"Module CompromiseEvaluators","title":"Module CompromiseEvaluators","text":"The methods below should be implemented to evaluate parameter dependent operators:","category":"page"},{"location":"CompromiseEvaluators/","page":"Module CompromiseEvaluators","title":"Module CompromiseEvaluators","text":"\"\"\"\n    eval_op!(y, op, x, p)\n\nEvaluate the operator `op` at variable vector `x` with parameters `p`\nand mutate the target vector `y` to contain the result.\n\"\"\"\nfunction eval_op!(y, op::AbstractNonlinearOperatorWithParams, x, p)\n    return error(\"No implementation of `eval_op!` for operator $op.\")\nend\n\n\"\"\"\n    eval_grads!(Dy, op, x, p)\n\nCompute the gradients of the operator `op` at variable vector `x` with parameters `p`\nand mutate the target matrix `Dy` to contain the gradients w.r.t. `x` in its columns.\nThat is, `Dy` is the transposed Jacobian at `x`.\n\"\"\"\nfunction eval_grads!(Dy, op::AbstractNonlinearOperatorWithParams, x, p)\n    return error(\"No implementation of `eval_grads!` for operator $op.\")\nend","category":"page"},{"location":"CompromiseEvaluators/","page":"Module CompromiseEvaluators","title":"Module CompromiseEvaluators","text":"The combined forward-function eval_op_and_grads! is derived from eval_op! and eval_grads!, but can be customized easily:","category":"page"},{"location":"CompromiseEvaluators/","page":"Module CompromiseEvaluators","title":"Module CompromiseEvaluators","text":"# helper macro `@serve` instead of `return`\nimport ..Compromise: @serve\n\nfunction eval_op_and_grads!(y, Dy, op::AbstractNonlinearOperatorWithParams, x, p)\n    @serve eval_op!(y, val, x, p)\n    @serve eval_grads!(Dy, val, x, p)\n    return nothing\nend","category":"page"},{"location":"CompromiseEvaluators/","page":"Module CompromiseEvaluators","title":"Module CompromiseEvaluators","text":"If Hessian matrices are needed, implement eval_hessians!(H, op, x, p). Assume H to be a 3D array, where the last index iterates over the function outputs. That is, H[:,:,1] is a matrix containing second order partial derivatives of the first output, H[:,:,2] has second order derivatives for the second output, and so forth... Moreover, in unlike with eval_grads!, the Hessian information should be stored in correct order - H[i,j,k] should correspond to ∂yₖ/∂xᵢ∂xⱼ. After eval_grads!(D, op, x, p), the column D[:,k] contains partial derivatives ∂₁yₖ, ∂₂yₖ, …, ∂ₘyₖ, the gradient of y[k]. After eval_hessians!(H, op, x, p), the “column” H[:, j, k] contains ∂₁(∂ⱼyₖ), ∂₂(∂ⱼyₖ), …, ∂ₘ(∂ⱼyₖ), the gradient of Dy[j, k].","category":"page"},{"location":"CompromiseEvaluators/","page":"Module CompromiseEvaluators","title":"Module CompromiseEvaluators","text":"\"\"\"\n    eval_hessians!(H, op, x, p)\n\nCompute the Hessians of the operator `op` at variable vector `x` with parameters `p`\nand mutate the target array `H` to contain the Hessians along its last index.\nThat is, `H[:,:,i]` is the Hessian at `x` and `p` w.r.t. `x` of output `i`.\n\"\"\"\nfunction eval_hessians!(H, op::AbstractNonlinearOperatorWithParams, x, p)\n    return error(\"No implementation of `eval_hessians!` for operator $op.\")\nend","category":"page"},{"location":"CompromiseEvaluators/","page":"Module CompromiseEvaluators","title":"Module CompromiseEvaluators","text":"The combined forward-function eval_op_and_grads_and_hessians! is derived from eval_op_and_grads! and eval_hessians!, but can be customized easily:","category":"page"},{"location":"CompromiseEvaluators/","page":"Module CompromiseEvaluators","title":"Module CompromiseEvaluators","text":"function eval_op_and_grads!(y, Dy, H, op::AbstractNonlinearOperatorWithParams, x, p)\n    @serve eval_op_and_grads!(Dy, y, op, x, p)\n    @serve eval_hessians!(H, val, x, p)\n    return nothing\nend","category":"page"},{"location":"CompromiseEvaluators/","page":"Module CompromiseEvaluators","title":"Module CompromiseEvaluators","text":"Some operators might support partial evaluation. They should implement these methods, if supports_partial_evaluation returns true. The argument outputs is an iterable of output indices, assuming 1 to be the first output. y is the full length vector, and partial_op! should set y[outputs].","category":"page"},{"location":"CompromiseEvaluators/","page":"Module CompromiseEvaluators","title":"Module CompromiseEvaluators","text":"function partial_op!(y, op::AbstractNonlinearOperatorWithParams, x, p, outputs)\n    # length(y)==length(outputs)\n    return error(\"Partial evaluation not implemented.\")\nend\nfunction partial_grads!(Dy, op::AbstractNonlinearOperatorWithParams, x, p, outputs)\n    # size(Dy)==(length(x), length(outputs))\n    return error(\"Partial Jacobian not implemented.\")\nend\nfunction partial_op_and_grads!(y, Dy, op::AbstractNonlinearOperatorWithParams, x, p, outputs)\n    @serve partial_op!(y, op, x, p, outputs)\n    @serve partial_grads!(Dy, op, x, p, outputs)\n    return nothing\nend\nfunction partial_hessians!(H, op::AbstractNonlinearOperatorWithParams, x, p, outputs)\n    return error(\"Partial Hessians not implemented.\")\nend\nfunction partial_op_and_grads_and_hessians!(y, Dy, H, op::AbstractNonlinearOperatorWithParams, x, p, outputs)\n    @serve partial_op_and_grads!(y, Dy, op, x, p, outputs)\n    @serve partial_hessians!(H, op, x, p, outputs)\n    return nothing\nend","category":"page"},{"location":"CompromiseEvaluators/","page":"Module CompromiseEvaluators","title":"Module CompromiseEvaluators","text":"From the above, we derive safe-guarded functions, that can be used to pass outputs whenever convenient. Note, that these are defined for AbstractNonlinearOperator. By implementing the parametric-interface for AbstractNonlinearOperatorNoParams, they work out-of-the box for non-paremetric operators, too:","category":"page"},{"location":"CompromiseEvaluators/","page":"Module CompromiseEvaluators","title":"Module CompromiseEvaluators","text":"function check_num_calls(op, ind; force::Bool=enforce_max_calls(op))\n    !is_counted(op) && return nothing\n    !force && return nothing\n    max_call_tuple = max_calls(op)\n    isnothing(max_call_tuple) && return nothing\n    ncalls = num_calls(op)\n    for i=ind\n        ni = ncalls[i]\n        mi = max_call_tuple[i]\n        isnothing(mi) && continue\n        if ni >= mi\n            return \"Maximum evaluation count reached, order=$(i-1), evals $(ni) >= $(mi).\"\n        end\n    end\n    return nothing\nend\n\nfunction func_vals!(y, op::AbstractNonlinearOperator, x, p; outputs=nothing)\n    @serve check_num_calls(op, 1)\n    if !isnothing(outputs) && supports_partial_evaluation(op)\n        return partial_op!(y, op, x, p, outputs)\n    end\n    return eval_op!(y, op, x, p)\nend\nfunction func_grads!(Dy, op::AbstractNonlinearOperator, x, p; outputs=nothing)\n    @serve check_num_calls(op, 2)\n    if !isnothing(outputs) && supports_partial_evaluation(op)\n        return partial_grads!(Dy, op, x, p, outputs)\n    end\n    return eval_grads!(Dy, op, x, p)\nend\nfunction func_vals_and_grads!(y, Dy, op::AbstractNonlinearOperator, x, p; outputs=nothing)\n    @serve check_num_calls(op, (1,2))\n    if !isnothing(outputs) && supports_partial_evaluation(op)\n        return partial_op_and_grads!(y, Dy, op, x, p, outputs)\n    end\n    return eval_op_and_grads!(y, Dy, op, x, p)\nend\nfunction func_hessians!(H, op::AbstractNonlinearOperator, x, p; outputs=nothing)\n    @serve check_num_calls(op, 3)\n    if !isnothing(outputs) && supports_partial_evaluation(op)\n        return partial_hessians!(H, op, x, p, outputs)\n    end\n    return eval_hessians!(H, op, x, p)\nend\nfunction func_vals_and_grads_and_hessians!(\n    y, Dy, H, op::AbstractNonlinearOperator, x, p; outputs=nothing)\n    @serve check_num_calls(op, (1,2,3))\n    if !isnothing(outputs) && supports_partial_evaluation(op)\n        return partial_op_and_grads_and_hessians!(y, Dy, H, op, x, p, outputs)\n    end\n    return eval_op_and_grads_and_hessians!(y, Dy, H, op, x, p)\nend","category":"page"},{"location":"CompromiseEvaluators/#Methods-AbstractNonlinearOperatorNoParams","page":"Module CompromiseEvaluators","title":"Methods AbstractNonlinearOperatorNoParams","text":"","category":"section"},{"location":"CompromiseEvaluators/","page":"Module CompromiseEvaluators","title":"Module CompromiseEvaluators","text":"The interface for operators without parameters is very similar to what's above. In fact, we could always treat it as a special case of AbstractNonlinearOperatorWithParams and simply ignore the parameter vector. However, in some situation it might be desirable to have the methods without p readily at hand. This also makes writing extensions a tiny bit easier.","category":"page"},{"location":"CompromiseEvaluators/","page":"Module CompromiseEvaluators","title":"Module CompromiseEvaluators","text":"function eval_op!(y, op::AbstractNonlinearOperatorNoParams, x)\n    return error(\"No implementation of `eval_op!` for operator $op.\")\nend\nfunction eval_grads!(Dy, op::AbstractNonlinearOperatorNoParams, x)\n    return error(\"No implementation of `eval_grads!` for operator $op.\")\nend","category":"page"},{"location":"CompromiseEvaluators/","page":"Module CompromiseEvaluators","title":"Module CompromiseEvaluators","text":"Optional, derived method for values and gradients:","category":"page"},{"location":"CompromiseEvaluators/","page":"Module CompromiseEvaluators","title":"Module CompromiseEvaluators","text":"function eval_op_and_grads!(y, Dy, op::AbstractNonlinearOperatorNoParams, x)\n    @serve eval_op!(y, op, x)\n    @serve eval_grads!(Dy, op, x)\n    return nothing\nend","category":"page"},{"location":"CompromiseEvaluators/","page":"Module CompromiseEvaluators","title":"Module CompromiseEvaluators","text":"Same for Hessians:","category":"page"},{"location":"CompromiseEvaluators/","page":"Module CompromiseEvaluators","title":"Module CompromiseEvaluators","text":"function eval_hessians!(H, op::AbstractNonlinearOperatorNoParams, x)\n    return error(\"No implementation of `eval_hessians!` for operator $op.\")\nend\nfunction eval_op_and_grads_and_hessians!(y, Dy, H, op::AbstractNonlinearOperatorNoParams, x)\n    @serve eval_op_and_grads!(y, Dy, op, x)\n    @serve eval_hessians!(H, op, x)\n    return nothing\nend","category":"page"},{"location":"CompromiseEvaluators/","page":"Module CompromiseEvaluators","title":"Module CompromiseEvaluators","text":"Some operators might support partial evaluation. They should implement these methods, if supports_partial_evaluation returns true:","category":"page"},{"location":"CompromiseEvaluators/","page":"Module CompromiseEvaluators","title":"Module CompromiseEvaluators","text":"function partial_op!(y, op::AbstractNonlinearOperatorNoParams, x, outputs)\n    return error(\"Partial evaluation not implemented.\")\nend\nfunction partial_grads!(Dy, op::AbstractNonlinearOperatorNoParams, x, outputs)\n    return error(\"Partial Jacobian not implemented.\")\nend\nfunction partial_op_and_grads!(y, Dy, op::AbstractNonlinearOperatorNoParams, x, outputs)\n    @serve partial_op!(y, op, x, outputs)\n    @serve partial_grads!(Dy, op, x, outputs)\n    return nothing\nend\nfunction partial_hessians!(H, op::AbstractNonlinearOperatorNoParams, x, outputs)\n    return error(\"Partial Hessians not implemented.\")\nend\nfunction partial_op_and_grads_and_hessians!(y, Dy, H, op::AbstractNonlinearOperatorNoParams, x, outputs)\n    @serve partial_op_and_grads!(y, Dy, op, x, outputs)\n    @serve partial_hessians!(H, op, x, outputs)\n    return nothing\nend","category":"page"},{"location":"CompromiseEvaluators/#Parameter-Methods-for-Non-Parametric-Operators","page":"Module CompromiseEvaluators","title":"Parameter-Methods for Non-Parametric Operators","text":"","category":"section"},{"location":"CompromiseEvaluators/","page":"Module CompromiseEvaluators","title":"Module CompromiseEvaluators","text":"To also be able to use non-parametric operators in the more general setting, implement the parametric-interface:","category":"page"},{"location":"CompromiseEvaluators/","page":"Module CompromiseEvaluators","title":"Module CompromiseEvaluators","text":"function eval_op!(y, op::AbstractNonlinearOperatorNoParams, x, p)\n    return eval_op!(y, op, x)\nend\nfunction eval_grads!(Dy, op::AbstractNonlinearOperatorNoParams, x, p)\n    return eval_grads!(Dy, op, x)\nend\nfunction eval_op_and_grads!(y, Dy, op::AbstractNonlinearOperatorNoParams, x, p)\n    return eval_op_and_grads!(y, Dy, op, x)\nend\nfunction eval_hessians!(H, op::AbstractNonlinearOperatorNoParams, x, p)\n    return eval_hessians!(H, op, x)\nend\nfunction eval_op_and_grads_and_hessians!(y, Dy, H, op::AbstractNonlinearOperatorNoParams, x, p)\n    return eval_op_and_grads_and_hessians!(y, Dy, H, op, x)\nend","category":"page"},{"location":"CompromiseEvaluators/","page":"Module CompromiseEvaluators","title":"Module CompromiseEvaluators","text":"Partial evaluation or differentiation:","category":"page"},{"location":"CompromiseEvaluators/","page":"Module CompromiseEvaluators","title":"Module CompromiseEvaluators","text":"function partial_op!(y, op::AbstractNonlinearOperatorNoParams, x, p, outputs)\n    return partial_op!(y, op, x, outputs)\nend\nfunction partial_grads!(Dy, op::AbstractNonlinearOperatorNoParams, x, p, outputs)\n    return partial_grads!(Dy, op, x, outputs)\nend\nfunction partial_op_and_grads!(y, Dy, op::AbstractNonlinearOperatorNoParams, x, p, outputs)\n    return partial_op_and_grads!(y, Dy, op, x, outputs)\nend\nfunction partial_hessians!(H, op::AbstractNonlinearOperatorNoParams, x, p, outputs)\n    return partial_hessians!(H, op, x, outputs)\nend\nfunction partial_op_and_grads_and_hessians!(\n    y, Dy, H, op::AbstractNonlinearOperatorNoParams, x, p, outputs\n)\n    return partial_op_and_grads_and_hessians!(y, Dy, H, op, x, outputs)\nend","category":"page"},{"location":"CompromiseEvaluators/","page":"Module CompromiseEvaluators","title":"Module CompromiseEvaluators","text":"The safe-guarded methods can now simply forward to the parametric versions and pass nothing parameters:","category":"page"},{"location":"CompromiseEvaluators/","page":"Module CompromiseEvaluators","title":"Module CompromiseEvaluators","text":"function func_vals!(y, op::AbstractNonlinearOperator, x; outputs=nothing)\n    return func_vals!(y, op, x, nothing; outputs)\nend\nfunction func_grads!(Dy, op::AbstractNonlinearOperator, x; outputs=nothing)\n    return func_grads!(Dy, op, x, nothing; outputs)\nend\nfunction func_vals_and_grads!(y, Dy, op::AbstractNonlinearOperator, x; outputs=nothing)\n    return func_vals_and_grads!(y, Dy, op, x, nothing; outputs)\nend\nfunction func_hessians!(H, op::AbstractNonlinearOperator, x; outputs=nothing)\n    return func_hessians!(H, op, x, nothing; outputs)\nend\nfunction func_vals_and_grads_and_hessians!(\n    y, Dy, H, op::AbstractNonlinearOperator, x; outputs=nothing\n)\n    return func_vals_and_grads_and_hessians!(y, Dy, H, op, x, nothing; outputs)\nend","category":"page"},{"location":"CompromiseEvaluators/#Non-Parametric-Methods-for-Parametric-Operators","page":"Module CompromiseEvaluators","title":"Non-Parametric Methods for Parametric Operators","text":"","category":"section"},{"location":"CompromiseEvaluators/","page":"Module CompromiseEvaluators","title":"Module CompromiseEvaluators","text":"These should only be used when you know what you are doing, as we set the parameters to nothing. This is safe only if we now that an underlying function is not-parametric, but somehow wrapped in something implementing AbstractNonlinearOperatorWithParams.","category":"page"},{"location":"CompromiseEvaluators/","page":"Module CompromiseEvaluators","title":"Module CompromiseEvaluators","text":"function eval_op!(y, op::AbstractNonlinearOperatorWithParams, x)\n    return eval_op!(y, op, x, nothing)\nend\nfunction eval_grads!(Dy, op::AbstractNonlinearOperatorWithParams, x)\n    return eval_grads!(Dy, op, x, nothing)\nend\n\nfunction eval_op_and_grads!(y, Dy, op::AbstractNonlinearOperatorWithParams, x)\n    return eval_op_and_grads!(y, Dy, op, x, nothing)\nend\n\nfunction eval_hessians!(H, op::AbstractNonlinearOperatorWithParams, x)\n    return eval_hessians!(H, op, x, nothing)\nend\n\nfunction eval_op_and_grads_and_hessians!(y, Dy, H, op::AbstractNonlinearOperatorWithParams, x)\n    return eval_op_and_grads_and_hessians!(y, Dy, H, op, x, nothing)\nend\n\nfunction partial_op!(y, op::AbstractNonlinearOperatorWithParams, x, outputs)\n    return partial_op!(y, op, x, nothing, outputs)\nend\nfunction partial_grads!(Dy, op::AbstractNonlinearOperatorWithParams, x, outputs)\n    return partial_grads!(Dy, op, x, nothing, outputs)\nend\nfunction partial_op_and_grads!(y, Dy, op::AbstractNonlinearOperatorWithParams, x, outputs)\n    return partial_op_and_grads!(y, Dy, op, x, nothing, outputs)\nend\nfunction partial_hessians!(H, op::AbstractNonlinearOperatorWithParams, x, outputs)\n    return partial_hessians!(H, op, x, nothing, outputs)\nend\nfunction partial_op_and_grads_and_hessians!(\n    y, Dy, H, op::AbstractNonlinearOperatorWithParams, x, outputs\n)\n    return partial_op_and_grads_and_hessians!(y, Dy, H, op, x, nothing, outputs)\nend","category":"page"},{"location":"CompromiseEvaluators/#Types-and-Methods-for-Surrogate-Models","page":"Module CompromiseEvaluators","title":"Types and Methods for Surrogate Models","text":"","category":"section"},{"location":"CompromiseEvaluators/","page":"Module CompromiseEvaluators","title":"Module CompromiseEvaluators","text":"An AbstractSurrogateModel is similar to AbstractNonlinearOperator. Such a surrogate model is always non-parametric, as parameters of operators are assumed to be fix in between runs.","category":"page"},{"location":"CompromiseEvaluators/","page":"Module CompromiseEvaluators","title":"Module CompromiseEvaluators","text":"abstract type AbstractSurrogateModel end","category":"page"},{"location":"CompromiseEvaluators/","page":"Module CompromiseEvaluators","title":"Module CompromiseEvaluators","text":"We also want to be able to define the behavior of models with light-weight objects:","category":"page"},{"location":"CompromiseEvaluators/","page":"Module CompromiseEvaluators","title":"Module CompromiseEvaluators","text":"abstract type AbstractSurrogateModelConfig end","category":"page"},{"location":"CompromiseEvaluators/#Indicator-Methods","page":"Module CompromiseEvaluators","title":"Indicator Methods","text":"","category":"section"},{"location":"CompromiseEvaluators/","page":"Module CompromiseEvaluators","title":"Module CompromiseEvaluators","text":"Functions to indicate the order of the surrogate model:","category":"page"},{"location":"CompromiseEvaluators/","page":"Module CompromiseEvaluators","title":"Module CompromiseEvaluators","text":"requires_grads(::AbstractSurrogateModelConfig)=false\nrequires_hessians(::AbstractSurrogateModelConfig)=false","category":"page"},{"location":"CompromiseEvaluators/","page":"Module CompromiseEvaluators","title":"Module CompromiseEvaluators","text":"A function to indicate that a model should be updated when the trust region has changed:","category":"page"},{"location":"CompromiseEvaluators/","page":"Module CompromiseEvaluators","title":"Module CompromiseEvaluators","text":"depends_on_radius(::AbstractSurrogateModel)=true","category":"page"},{"location":"CompromiseEvaluators/#Initialization-and-Modification","page":"Module CompromiseEvaluators","title":"Initialization and Modification","text":"","category":"section"},{"location":"CompromiseEvaluators/","page":"Module CompromiseEvaluators","title":"Module CompromiseEvaluators","text":"The choice to don't separate between a model and its parameters (like Lux.jl does) is historic. There are pros and cons to both approaches. The most obvious point in favor of how it is now are the unified evaluation interfaces. However, for the Criticality Routine we might need to copy models and retrain them for smaller trust-region radii. That is why we require implementation of copy_model(source_model) and copyto_model!(trgt_model, src_model). A modeller should take care to really only copy parameter arrays and pass other large objects, such as databases, by reference so as to avoid a large memory-overhead. Moreover, we only need copies for radius-dependent models! You can ignore those methods otherwise.","category":"page"},{"location":"CompromiseEvaluators/","page":"Module CompromiseEvaluators","title":"Module CompromiseEvaluators","text":"A surrogate is initialized from its configuration and the operator it is meant to model:","category":"page"},{"location":"CompromiseEvaluators/","page":"Module CompromiseEvaluators","title":"Module CompromiseEvaluators","text":"\"\"\"\n    init_surrogate(\n        model_config, nonlin_op, dim_in, dim_out, params, T\n    )\n\nReturn a model subtyping `AbstractSurrogateModel`, as defined by\n`model_config::AbstractSurrogateModelConfig`, for the nonlinear operator `nonlin_op`.\nThe operator (and model) has input dimension `dim_in` and output dimension `dim_out`.\n`params` is the current parameter object for `nonlin_op` and is cached.\n`T` is a subtype of `AbstractFloat` to indicate precision of cache arrays.\n\"\"\"\nfunction init_surrogate(\n    ::AbstractSurrogateModelConfig, op, dim_in, dim_out, params, T)::AbstractSurrogateModel\n    return nothing\nend","category":"page"},{"location":"CompromiseEvaluators/","page":"Module CompromiseEvaluators","title":"Module CompromiseEvaluators","text":"A function to return a copy of a model. Should be implemented if depends_on_radius returns true. Note, that the returned object does not have to be an “independent” copy, we allow for shared objects (like mutable database arrays or something of that sort)...","category":"page"},{"location":"CompromiseEvaluators/","page":"Module CompromiseEvaluators","title":"Module CompromiseEvaluators","text":"copy_model(mod_src)=deepcopy(mod_src)","category":"page"},{"location":"CompromiseEvaluators/","page":"Module CompromiseEvaluators","title":"Module CompromiseEvaluators","text":"A function to copy parameters between source and target models, like Base.copy! or Base.copyto!. Relevant mostly for trainable parameters.","category":"page"},{"location":"CompromiseEvaluators/","page":"Module CompromiseEvaluators","title":"Module CompromiseEvaluators","text":"copyto_model!(mod_trgt::AbstractSurrogateModel, mod_src::AbstractSurrogateModel)=mod_trgt\n\nfunction _copy_model(mod)\n    depends_on_radius(mod) && return copy_model(mod)\n    return mod\nend\n\nfunction _copyto_model!(mod_trgt, mod_src)\n    depends_on_radius(mod_trgt) && return copyto_model!(mod_trgt, mod_src)\n    return mod_trgt\nend","category":"page"},{"location":"CompromiseEvaluators/","page":"Module CompromiseEvaluators","title":"Module CompromiseEvaluators","text":"Because parameters are implicit, updates are in-place operations:","category":"page"},{"location":"CompromiseEvaluators/","page":"Module CompromiseEvaluators","title":"Module CompromiseEvaluators","text":"\"\"\"\n    update!(surrogate_model, nonlinear_operator, Δ, x, fx, lb, ub)\n\nUpdate the model on a trust region of size `Δ` in a box with lower left corner `lb`\nand upper right corner `ub` (in the scaled variable domain)\n`x` is a sub-vector of the current iterate conforming to the inputs of `nonlinear_operator`\nin the scaled domain. `fx` are the outputs of `nonlinear_operator` at `x`.\n\"\"\"\nfunction update!(\n    surr::AbstractSurrogateModel, op, Δ, x, fx, lb, ub; kwargs...\n)\n    return nothing\nend","category":"page"},{"location":"CompromiseEvaluators/#Evaluation","page":"Module CompromiseEvaluators","title":"Evaluation","text":"","category":"section"},{"location":"CompromiseEvaluators/","page":"Module CompromiseEvaluators","title":"Module CompromiseEvaluators","text":"In place evaluation and differentiation, similar to AbstractNonlinearOperatorNoParams. Mandatory:","category":"page"},{"location":"CompromiseEvaluators/","page":"Module CompromiseEvaluators","title":"Module CompromiseEvaluators","text":"function model_op!(y, surr::AbstractSurrogateModel, x)\n    return nothing\nend","category":"page"},{"location":"CompromiseEvaluators/","page":"Module CompromiseEvaluators","title":"Module CompromiseEvaluators","text":"Mandatory:","category":"page"},{"location":"CompromiseEvaluators/","page":"Module CompromiseEvaluators","title":"Module CompromiseEvaluators","text":"function model_grads!(Dy, surr::AbstractSurrogateModel, x)\n    return nothing\nend","category":"page"},{"location":"CompromiseEvaluators/","page":"Module CompromiseEvaluators","title":"Module CompromiseEvaluators","text":"Optional:","category":"page"},{"location":"CompromiseEvaluators/","page":"Module CompromiseEvaluators","title":"Module CompromiseEvaluators","text":"function model_op_and_grads!(y, Dy, surr::AbstractSurrogateModel, x)\n    model_op!(y, surr, x )\n    model_grads!(Dy, surr, x)\n    return nothing\nend","category":"page"},{"location":"CompromiseEvaluators/#Optional-Partial-Evaluation","page":"Module CompromiseEvaluators","title":"Optional Partial Evaluation","text":"","category":"section"},{"location":"CompromiseEvaluators/","page":"Module CompromiseEvaluators","title":"Module CompromiseEvaluators","text":"supports_partial_evaluation(::AbstractSurrogateModel)=false\nfunction model_op!(y, surr::AbstractSurrogateModel, x, outputs)\n    return error(\"Surrogate model does not support partial evaluation.\")\nend\nfunction model_grads!(y, surr::AbstractSurrogateModel, x, outputs)\n    return error(\"Surrogate model does not support partial Jacobian.\")\nend\nfunction model_op_and_grads!(y, Dy, surr::AbstractSurrogateModel, x, outputs)\n    model_op!(y, surr, x, outputs)\n    model_grads!(y, surr, x, outputs)\n    return nothing\nend","category":"page"},{"location":"CompromiseEvaluators/#Safe-guarded,-internal-Methods","page":"Module CompromiseEvaluators","title":"Safe-guarded, internal Methods","text":"","category":"section"},{"location":"CompromiseEvaluators/","page":"Module CompromiseEvaluators","title":"Module CompromiseEvaluators","text":"The methods below are used in the algorithm and have the same signature as the corresponding methods for AbstractNonlinearOperator. Thus, we do not have to distinguish types in practice.","category":"page"},{"location":"CompromiseEvaluators/","page":"Module CompromiseEvaluators","title":"Module CompromiseEvaluators","text":"function func_vals!(y, surr::AbstractSurrogateModel, x, p, outputs=nothing)\n    if !isnothing(outputs)\n        if supports_partial_evaluation(surr)\n            return model_op!(y, surr, x, outputs)\n        # else\n        #     @warn \"Partial evaluation not supported by surrogate model.\"\n        end\n    end\n    return model_op!(y, surr, x)\nend\nfunction func_grads!(Dy, surr::AbstractSurrogateModel, x, p, outputs=nothing)\n    if !isnothing(outputs)\n        if supports_partial_evaluation(surr)\n            return model_grads!(Dy, surr, x, outputs)\n        # else\n        #     @warn \"Partial evaluation not supported by surrogate model.\"\n        end\n    end\n    return model_grads!(Dy, surr, x)\nend\nfunction func_vals_and_grads!(y, Dy, surr::AbstractSurrogateModel, x, p, outputs=nothing)\n    if !isnothing(outputs)\n        if supports_partial_evaluation(surr)\n            return model_op_and_grads!(y, Dy, surr, x, outputs)\n        # else\n        #     @warn \"Partial evaluation not supported by surrogate model.\"\n        end\n    end\n    return model_op_and_grads!(y, Dy, surr, x)\nend","category":"page"},{"location":"CompromiseEvaluators/#Module-Exports","page":"Module CompromiseEvaluators","title":"Module Exports","text":"","category":"section"},{"location":"CompromiseEvaluators/","page":"Module CompromiseEvaluators","title":"Module CompromiseEvaluators","text":"export AbstractNonlinearOperator, AbstractNonlinearOperatorNoParams, AbstractNonlinearOperatorWithParams\nexport AbstractSurrogateModel, AbstractSurrogateModelConfig\nexport supports_partial_evaluation, provides_grads, provides_hessians, requires_grads, requires_hessians\nexport func_vals!, func_grads!, func_hessians!, func_vals_and_grads!, func_vals_and_grads_and_hessians!\nexport eval_op!, eval_grads!, eval_hessians!, eval_op_and_grads!, eval_op_and_grads_and_hessians!\nexport func_vals!, func_grads!, func_vals_and_grads!, func_vals_and_grads_and_hessians!\nexport model_op!, model_grads!, model_op_and_grads!\nexport init_surrogate, update!\n\nend#module","category":"page"},{"location":"CompromiseEvaluators/","page":"Module CompromiseEvaluators","title":"Module CompromiseEvaluators","text":"","category":"page"},{"location":"CompromiseEvaluators/","page":"Module CompromiseEvaluators","title":"Module CompromiseEvaluators","text":"This page was generated using Literate.jl.","category":"page"},{"location":"rbf_database_callback/","page":"RBF Data Sharing","title":"RBF Data Sharing","text":"EditURL = \"../literate_src/rbf_database_callback.jl\"","category":"page"},{"location":"rbf_database_callback/#Sharing-Model-Data-Between-Runs","page":"RBF Data Sharing","title":"Sharing Model Data Between Runs","text":"","category":"section"},{"location":"rbf_database_callback/","page":"RBF Data Sharing","title":"RBF Data Sharing","text":"Sharing and Recycling surrogate models is not yet part of the public API. Below is a hack to do so nonetheless by abusing the user_callback functionality.","category":"page"},{"location":"rbf_database_callback/","page":"RBF Data Sharing","title":"RBF Data Sharing","text":"import Compromise","category":"page"},{"location":"rbf_database_callback/","page":"RBF Data Sharing","title":"RBF Data Sharing","text":"The ModelCapturer can store a reference to the surrogate and the variable scaler:","category":"page"},{"location":"rbf_database_callback/","page":"RBF Data Sharing","title":"RBF Data Sharing","text":"mutable struct ModelCapturer  <: Compromise.AbstractStoppingCriterion\n    mod :: Any\n    scaler :: Any\n    active :: Bool\nend","category":"page"},{"location":"rbf_database_callback/","page":"RBF Data Sharing","title":"RBF Data Sharing","text":"Its logic is to snatch that reference before the first iteration takes place …","category":"page"},{"location":"rbf_database_callback/","page":"RBF Data Sharing","title":"RBF Data Sharing","text":"Compromise.check_pre_iteration(crit::ModelCapturer)=crit.active","category":"page"},{"location":"rbf_database_callback/","page":"RBF Data Sharing","title":"RBF Data Sharing","text":"… or copy the model parameters to the model mod in use, if a reference is already stored:","category":"page"},{"location":"rbf_database_callback/","page":"RBF Data Sharing","title":"RBF Data Sharing","text":"function Compromise.evaluate_stopping_criterion(\n    crit::ModelCapturer,\n    Δ, mop, mod, scaler, lin_cons, scaled_cons,\n    vals, vals_tmp, step_vals, mod_vals, filter, iter_meta, step_cache, algo_opts;\n)\n    if isnothing(crit.scaler)\n        crit.scaler = scaler\n    end\n    if isnothing(crit.mod)\n        crit.mod = mod\n        crit.active = false\n    else\n        Compromise._copyto_model!(mod, crit.mod)\n        crit.active = false\n    end\n    return nothing\nend","category":"page"},{"location":"rbf_database_callback/","page":"RBF Data Sharing","title":"RBF Data Sharing","text":"Running the optimization works as usual, we just store some data in our matrices X, X0, Y, etc.","category":"page"},{"location":"rbf_database_callback/","page":"RBF Data Sharing","title":"RBF Data Sharing","text":"import HaltonSequences: HaltonPoint\nimport Logging\nfunction run_problems(lb, ub, objf!; num_runs::Int, reuse_model::Bool)\n    mop = Compromise.MutableMOP(; num_vars=2, lb, ub)\n\n    Compromise.add_objectives!(\n        mop, objf!, :rbf;\n        dim_out=2, func_iip=true,\n    )\n\n    algo_opts = Compromise.AlgorithmOptions(;\n        log_level=Logging.Debug,\n        stop_max_crit_loops=2,\n    )\n\n    user_callback = ModelCapturer(nothing, nothing, true)\n\n    wb = ub .- lb\n    scale_x = x -> lb .+ wb .* x\n    X0 = mapreduce(scale_x, hcat, HaltonPoint(2; length=num_runs))\n\n    X = Matrix{Float64}(undef, 2, num_runs)\n    Y0 = Matrix{Float64}(undef, 2, num_runs)\n    Y = Matrix{Float64}(undef, 2, num_runs)\n    database_x = Dict{Int, Matrix{Float64}}()\n    database_y = Dict{Int, Matrix{Float64}}()\n\n    for i = 1:num_runs\n        user_callback.active=true\n        if !reuse_model\n            user_callback.mod=nothing\n        end\n        x0 = @view(X0[:, i])\n        y0 = @view(Y0[:, i])\n        objf!(y0, x0)\n        fv, r = Compromise.optimize(mop, x0; algo_opts, user_callback)\n        X[:,i] .= fv.ξ\n        Y[:,i] .= fv.fx\n        db = user_callback.mod.mod_objectives.database\n        db_x = db.database_x[:, db.database_flags_x]\n        # input sites are scaled, we have to undo that:\n        database_x[i] = copy(db_x)\n        for (ci,c) in enumerate(eachcol(database_x[i]))\n            Compromise.unscale!(c, user_callback.scaler, db_x[:, ci])\n        end\n        database_y[i] = copy(db.database_y[:, db.database_flags_y])\n    end\n\n    return X, X0, database_x, Y, Y0, database_y\nend","category":"page"},{"location":"rbf_database_callback/#Plotting","page":"RBF Data Sharing","title":"Plotting","text":"","category":"section"},{"location":"rbf_database_callback/","page":"RBF Data Sharing","title":"RBF Data Sharing","text":"Below are all the plotting functions, you can skip these definitions.","category":"page"},{"location":"rbf_database_callback/","page":"RBF Data Sharing","title":"RBF Data Sharing","text":"using CairoMakie\nfunction matrix_lims(Y::Matrix)\n    lims1, lims2 = extrema(Y; dims=2)\n    return lims1, lims2\nend\n\nfunction matrix_lims(Ys...)\n    lims1 = (Inf, -Inf)\n    lims2 = (Inf, -Inf)\n    for Y in Ys\n        l1, l2 = matrix_lims(Y)\n        lims1 = (min(lims1[1], l1[1]), max(lims1[2], l1[2]))\n        lims2 = (min(lims2[1], l2[1]), max(lims2[2], l2[2]))\n    end\n    w1 = lims1[2] - lims1[1]\n    w2 = lims2[2] - lims2[1]\n    lims1 = (lims1[1] - w1/10, lims1[2] + w1/10)\n    lims2 = (lims2[1] - w2/10, lims2[2] + w2/10)\n    return lims1, lims2\nend","category":"page"},{"location":"rbf_database_callback/","page":"RBF Data Sharing","title":"RBF Data Sharing","text":"The animation plots a starting point in red, the final value in green, and database points in orange:","category":"page"},{"location":"rbf_database_callback/","page":"RBF Data Sharing","title":"RBF Data Sharing","text":"function make_animation(file_name, lb, ub, X, X0, database_x, Y, Y0, database_y; ylims1=nothing, ylims2=nothing)\n\n    pX0 = Observable(Point2[])\n    pX = Observable(Point2[])\n    pXdb = Observable(Point2[])\n    pY0 = Observable(Point2[])\n    pY = Observable(Point2[])\n    pYdb = Observable(Point2[])\n\n    fig = Figure()\n    # Plot Input Space\n    ax1 = Axis(fig[1,1])\n    wb = ub .- lb\n    xlims!(ax1, (lb[1] - wb[1]/10 , ub[1] + wb[1]/10))\n    ylims!(ax1, (lb[2] - wb[2]/10 , ub[2] + wb[2]/10))\n\n    # Plot Output Space\n    ax2 = Axis(fig[1,2])\n    if !isnothing(ylims1)\n        xlims!(ax2, ylims1)\n    end\n    if !isnothing(ylims2)\n        ylims!(ax2, ylims2)\n    end\n\n    # make empty initial plots\n    scatter!(ax1, pXdb; color=:orange, markersize=25)\n    scatter!(ax1, pX0; color=:red)\n    scatter!(ax1, pX; color=:green)\n\n    scatter!(ax2, pYdb; color=:orange, markersize=25)\n    scatter!(ax2, pY0; color=:red)\n    scatter!(ax2, pY; color=:green)\n\n    i = 1\n    num_runs = size(X0, 2)\n    record(fig, joinpath(@__DIR__, file_name), 1:3*num_runs; framerate = 3) do _i\n        if _i % 3 == 1\n            x = Point2f(X0[1,i], X0[2,i])\n            y = Point2f(Y0[1,i], Y0[2,i])\n\n            pX0[] = push!(pX0[], x)\n            pY0[] = push!(pY0[], y)\n        elseif _i % 3 == 2\n            x = Point2f(X[1,i], X[2,i])\n            y = Point2f(Y[1,i], Y[2,i])\n            pX[] = push!(pX[], x)\n            pY[] = push!(pY[], y)\n        else\n            Xdb = database_x[i]\n            for xj in eachcol(Xdb)\n                x = Point2f(xj[1], xj[2])\n                pXdb[] = push!(pXdb[], x)\n            end\n            Ydb = database_y[i]\n            for yj in eachcol(Ydb)\n                y = Point2f(yj[1], yj[2])\n                pYdb[] = push!(pYdb[], y)\n            end\n            i+=1\n        end\n    end\nend","category":"page"},{"location":"rbf_database_callback/#Defining-Problems","page":"RBF Data Sharing","title":"Defining Problems","text":"","category":"section"},{"location":"rbf_database_callback/","page":"RBF Data Sharing","title":"RBF Data Sharing","text":"function lovison2()\n    lb = fill(-.5, 2)\n    ub = [0.0, 0.5]\n    objf!(y, x) = begin\n        y[1] = x[2]\n        y[2] = - (x[2]-x[1]^3)/(x[1]+1)\n        nothing\n    end\n    return lb, ub, objf!\nend\n\nfunction paraboloids()\n    lb = [-2, -2]\n    ub = [2, 2]\n    objf!(y, x) = begin\n        y[1] = sum( (x .- 1).^2 )\n        y[2] = sum( (x .+ 1).^2 )\n        nothing\n    end\n    return lb, ub, objf!\nend","category":"page"},{"location":"rbf_database_callback/#Lovison-2","page":"RBF Data Sharing","title":"Lovison 2","text":"","category":"section"},{"location":"rbf_database_callback/","page":"RBF Data Sharing","title":"RBF Data Sharing","text":"lb, ub, objf! = lovison2()\nres_noreuse = run_problems(lb, ub, objf!; num_runs=20, reuse_model=false)\nres_reuse = run_problems(lb, ub, objf!; num_runs=20, reuse_model=true)\n\nylims1, ylims2 = matrix_lims(\n    res_noreuse[4], res_noreuse[5], res_reuse[4], res_reuse[5])\n\nmake_animation(\"lovison2_noreuse.mp4\", lb, ub, res_noreuse...; ylims1, ylims2);\nnothing #hide","category":"page"},{"location":"rbf_database_callback/","page":"RBF Data Sharing","title":"RBF Data Sharing","text":"(Image: Lovison 2 -- No Data Sharing)","category":"page"},{"location":"rbf_database_callback/","page":"RBF Data Sharing","title":"RBF Data Sharing","text":"make_animation(\"lovison2_reuse.mp4\", lb, ub, res_reuse...; ylims1, ylims2);\nnothing #hide","category":"page"},{"location":"rbf_database_callback/","page":"RBF Data Sharing","title":"RBF Data Sharing","text":"(Image: Lovison 2 -- Data Sharing)","category":"page"},{"location":"rbf_database_callback/#2-Paraboloids","page":"RBF Data Sharing","title":"2 Paraboloids","text":"","category":"section"},{"location":"rbf_database_callback/","page":"RBF Data Sharing","title":"RBF Data Sharing","text":"lb, ub, objf! =paraboloids()\nres_noreuse = run_problems(lb, ub, objf!; num_runs=20, reuse_model=false)\nres_reuse = run_problems(lb, ub, objf!; num_runs=20, reuse_model=true)\n\nylims1, ylims2 = matrix_lims(\n    res_noreuse[4], res_noreuse[5], res_reuse[4], res_reuse[5])\n\nmake_animation(\"paraboloids_noreuse.mp4\", lb, ub, res_noreuse...; ylims1, ylims2);\nnothing #hide","category":"page"},{"location":"rbf_database_callback/","page":"RBF Data Sharing","title":"RBF Data Sharing","text":"(Image: Paraboloids -- No Data Sharing)","category":"page"},{"location":"rbf_database_callback/","page":"RBF Data Sharing","title":"RBF Data Sharing","text":"make_animation(\"paraboloids_reuse.mp4\", lb, ub, res_reuse...; ylims1, ylims2);\nnothing #hide","category":"page"},{"location":"rbf_database_callback/","page":"RBF Data Sharing","title":"RBF Data Sharing","text":"(Image: Paraboloids -- No Data Sharing)","category":"page"},{"location":"rbf_database_callback/","page":"RBF Data Sharing","title":"RBF Data Sharing","text":"","category":"page"},{"location":"rbf_database_callback/","page":"RBF Data Sharing","title":"RBF Data Sharing","text":"This page was generated using Literate.jl.","category":"page"},{"location":"README/","page":"README","title":"README","text":"EditURL = \"../literate_src/README.jl\"","category":"page"},{"location":"README/#Compromise.jl","page":"README","title":"Compromise.jl","text":"","category":"section"},{"location":"README/","page":"README","title":"README","text":"(Image: Stable) (Image: Dev) (Image: Build Status) (Image: Coverage)","category":"page"},{"location":"README/#About-“CoMPrOMISE”","page":"README","title":"About “CoMPrOMISE”","text":"","category":"section"},{"location":"README/","page":"README","title":"README","text":"Constrained Multiobjective Problem Optimizer with Model Information to Save Evaluations","category":"page"},{"location":"README/","page":"README","title":"README","text":"This package provides a flexible first-order solver for constrained and unconstrained nonlinear multi-objective problems. It uses a trust region approach and either exact derivatives or local surrogate models for a derivative-free descent. Box constraints are respected during model construction and treated as unrelaxable. Box constraints and linear constraints are supported and passed down to an inner LP solver. Nonlinear constraint functions can be modelled and are dealt with by incorporating a filter. They are relaxable, i.e., all other functions must be computable even when the constraints are violated.","category":"page"},{"location":"README/#Example","page":"README","title":"Example","text":"","category":"section"},{"location":"README/#Constrained-Two-Parabolas-Problem","page":"README","title":"Constrained Two-Parabolas Problem","text":"","category":"section"},{"location":"README/","page":"README","title":"README","text":"First we load the optimizer package, “Compromise.jl”:","category":"page"},{"location":"README/","page":"README","title":"README","text":"using Compromise","category":"page"},{"location":"README/","page":"README","title":"README","text":"The package exports a simple problem structure, MutableMOP. As the name suggests, this is a mutable structure to define a multi-objective optimization problem. We can use it to set up a problem step by step. The only information required for initialization is the number of variables:","category":"page"},{"location":"README/","page":"README","title":"README","text":"mop = MutableMOP(;num_vars = 2)","category":"page"},{"location":"README/","page":"README","title":"README","text":"For a MutableMOP, all functions are vector-to-vector. We can define the objectives (objectives), nonlinear inequality constraints (nl_ineq_constraints) and nonlinear equality constraints (nl_eq_constraints). By default, these fields default to nothing. Alternatively, they need objects of type Compromise.NonlinearFunction. We have helpers to support normal julia functions. For example, consider this vector-to-vector function:","category":"page"},{"location":"README/","page":"README","title":"README","text":"function objective_function(x)\n    return [\n        (x[1] - 2)^2 + (x[2] - 1)^2;\n        (x[1] - 2)^2 + (x[2] + 1)^2\n    ]\nend","category":"page"},{"location":"README/","page":"README","title":"README","text":"We can easily derive the gradients, so let's also define them manually, to use derivative-based models:","category":"page"},{"location":"README/","page":"README","title":"README","text":"function objective_grads(x)\n    # return the transposed Jacobian, i.e., gradients as columns\n    df11 = df21 = 2 * (x[1] - 2)\n    df12 = 2 * (x[2] - 1)\n    df22 = 2 * (x[2] + 1)\n    return [ df11 df21; df12 df22 ]\nend","category":"page"},{"location":"README/","page":"README","title":"README","text":"To add these functions to mop, we call the helper method add_objectives and also specify the model class to be used. There are shorthand symbols, for example :exact or taylor1, for objectives with known gradients. Alternatively, give some Compromise.A_bstractSurrogateModelConfig. We also have to tell the optimizer about the function signature. func_iip=true would imply an in-place objective with sigunature objective_function!(fx, x). dim_out is a mandatory argument.","category":"page"},{"location":"README/","page":"README","title":"README","text":"add_objectives!(\n    mop, objective_function, objective_grads, :taylor1;\n    dim_out=2, func_iip=false, grads_iip=false\n)","category":"page"},{"location":"README/","page":"README","title":"README","text":"note: Note\nFor the above objective function, it would be sensible to additionally have a function objective_values_and_grads, that returns the objectives and gradients at the same time. That is possible, MutableMOP has an interface for such optimizations.","category":"page"},{"location":"README/","page":"README","title":"README","text":"We support non-convex, nonlinear constraints (as long as they are relaxable). For example, we can constrain the problem to ℝ² without unit ball. For demonstration purposes, use an in-place function:","category":"page"},{"location":"README/","page":"README","title":"README","text":"nl_ineq_function!(y, x) = y[1] = 1 - sum(x.^2)","category":"page"},{"location":"README/","page":"README","title":"README","text":"Of course, that is a fairly simple constraint function. If it was more complicated, we could be tempted to use automatic differentiation for derivative calculations. Instead, you can also use derivative-free models, such as radial basis function (RBF) models.","category":"page"},{"location":"README/#Excursion:-RBF-Kernels","page":"README","title":"Excursion: RBF Kernels","text":"","category":"section"},{"location":"README/","page":"README","title":"README","text":"By default, a cubic kernel is used, if we use the :rbf option with add_nl_ineq_constraints!. To use the Gaussian kernel φ_ε(r) = exp(-(εr)^2) with fixed shape paramater 10, do","category":"page"},{"location":"README/","page":"README","title":"README","text":"rbf_config = RBFConfig(; kernel=GaussianKernel(10))","category":"page"},{"location":"README/","page":"README","title":"README","text":"There is other cool features. If you want to vary the shape parameter with the trust-region radius, you can give a function Δ  ε(Δ) to GaussianKernel (as well as InverseMultiQuadricKernel).","category":"page"},{"location":"README/","page":"README","title":"README","text":"gk = GaussianKernel(del -> min(1/del, 1_000))\nCompromise.RBFModels.shape_paramater(gk, 1) # equals 1.0\nCompromise.RBFModels.shape_paramater(gk, 0.0005) ## equals 1000","category":"page"},{"location":"README/","page":"README","title":"README","text":"For now, we stick with the fixed shape parameter and finalize our problem:","category":"page"},{"location":"README/","page":"README","title":"README","text":"add_nl_ineq_constraints!(mop, nl_ineq_function!, :rbf;\n    func_iip=true, dim_out=1\n)","category":"page"},{"location":"README/","page":"README","title":"README","text":"The MutableMOP is turned into a TypedMOP during initialization. We can thus simply pass it to optimize:","category":"page"},{"location":"README/","page":"README","title":"README","text":"final_vals, ret = optimize(mop, [-2.0, 0.5])","category":"page"},{"location":"README/","page":"README","title":"README","text":"ret is the return code. If no budget or time based stopping criterion was used, then CRITICAL is a nice return value, indicating a first-order critical point.","category":"page"},{"location":"README/","page":"README","title":"README","text":"final_vals is a ValueArrays object holding values at the final iteration site. final_vals.x is the parameter vector, final_vals.fx has the objective values. The nonlinear equality constraints are final_vals.hx, the inequality constraints are final_vals.gx...","category":"page"},{"location":"README/","page":"README","title":"README","text":"final_vals.x, final_vals.fx","category":"page"},{"location":"README/#Automatic-Diffentiation","page":"README","title":"Automatic Diffentiation","text":"","category":"section"},{"location":"README/","page":"README","title":"README","text":"There is an optional ForwardDiff extension. To use a derivative-based model without specifying the gradients by-hand, first load ForwardDiff.","category":"page"},{"location":"README/","page":"README","title":"README","text":"using ForwardDiff","category":"page"},{"location":"README/","page":"README","title":"README","text":"Now, ForwardDiffBackend should be available:","category":"page"},{"location":"README/","page":"README","title":"README","text":"diff_backend = ForwardDiffBackend()","category":"page"},{"location":"README/","page":"README","title":"README","text":"Set up the problem:","category":"page"},{"location":"README/","page":"README","title":"README","text":"mop = MutableMOP(2)\nadd_objectives!(mop, objective_function, :exact;\n    func_iip=false, dim_out=2, backend=diff_backend\n)\n\noptimize(mop, -5 .+ 10 .* rand(2))","category":"page"},{"location":"README/","page":"README","title":"README","text":"","category":"page"},{"location":"README/","page":"README","title":"README","text":"This page was generated using Literate.jl.","category":"page"},{"location":"dev_notes/#Developer-Notes","page":"(Dev) Notes","title":"Developer Notes","text":"","category":"section"},{"location":"dev_notes/#Function-Signatures","page":"(Dev) Notes","title":"Function Signatures","text":"","category":"section"},{"location":"dev_notes/","page":"(Dev) Notes","title":"(Dev) Notes","text":"For utility functions with few arguments, we try to keep to the Julia convention of appending an exclamation mark, if a method modifies some  of its arguments, and place those arguments first.","category":"page"},{"location":"dev_notes/","page":"(Dev) Notes","title":"(Dev) Notes","text":"However, some more complicated functions essential to the algorithm,  like do_iteration, do_restoration, compute_normal_step and compute_descent_step,  can require a multitude of arguments and keeping the correct order during development proves difficult. That is why in this case we use the standard signature","category":"page"},{"location":"dev_notes/","page":"(Dev) Notes","title":"(Dev) Notes","text":"function algo_function(\n    # iteration information\n    it_index, Δ, it_stat,\n    # objects to evaluate objectives, models and constraints\n    mop, mod, scaler, lin_cons, scaled_cons,\n    # caches for necessary arrays\n    vals, vals_tmp, step_vals, mod_vals, \n    # other important building blocks\n    filter,     # the filter used to drive feasibility\n    step_cache, # an object defining step calculation and holding caches\n    algo_opts;  # general algorithmic settings\n    # then follow custom keyword arguments …\n    custom_kwarg1, kwargs...\n)\n    # Function Body\nend","category":"page"},{"location":"dev_notes/","page":"(Dev) Notes","title":"(Dev) Notes","text":"We do not use keyword arguments to enable dispatch on custom configuration or cache types, e.g., in the case of compute_descent_step. What arguments are modified, or even guaranteed or required to be modified, should be made clear from docstrings or comments. The compiler does only specialize on function arguments if they are used within in  the function body, but not if they are merely passed through to other functions.","category":"page"},{"location":"dev_notes/#Medium-Priority-To-Do's","page":"(Dev) Notes","title":"Medium-Priority To-Do's","text":"","category":"section"},{"location":"dev_notes/","page":"(Dev) Notes","title":"(Dev) Notes","text":"Introduce AbstractSurrogateModelConfig to initialize AbstractSurrogateModel based on custom configuration objects instead of their types.\nMake dim_in or num_vars part of the AbstractMOP and AbstractMOPSurrogate interface.\nAdd dimension information to AbstractNonlinearOperator and AbstractSurrogateModel.   When this is done, some method signatures concerning initialization and updates can be   simplified. (CTRL-F for dim_in, num_vars, num_out, dim_out etc.)\nIn the modelling and DAG framework, switch names and meaning of dependent variables and   states. ","category":"page"},{"location":"","page":"Home","title":"Home","text":"CurrentModule = Compromise","category":"page"},{"location":"#Compromise","page":"Home","title":"Compromise","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Documentation for Compromise. There is not much here yet. Everything is still very much a work-in-progress.","category":"page"},{"location":"","page":"Home","title":"Home","text":"Random Doc-Strings:","category":"page"},{"location":"","page":"Home","title":"Home","text":"","category":"page"},{"location":"","page":"Home","title":"Home","text":"Modules = [Compromise.NonlinearFunctions, Compromise,]","category":"page"},{"location":"#Compromise.NonlinearFunctions.NonlinearParametricFunction","page":"Home","title":"Compromise.NonlinearFunctions.NonlinearParametricFunction","text":"NonlinearParametricFunction(; \n    func, grads=nothing, hessians=nothing, \n    func_and_grads=nothing, func_and_grads_and_hessians=nothing,\n    backend=nothing,\n    func_iip=true, grads_iip=true, hessians_iip=true, \n    func_and_grads_iip=true, func_and_grads_and_hessians_iip=true)\n\nA flexible function wrapper to conveniently query evaluations and derivatives of user provided functions.\n\nIf the user provided function is used in a derivative-free alogrithm, only func has  to be provided. The flag func_iip indicates its signature: If func_iip==true, the function should mutate the target array and  have signature func!(y, x, p). Otherwise, y = func(x, p).\n\nShould gradients be needed, function handles can be provided, and the respective  flags indicate the following signatures:\n\ngrads_iip == true implies grads!(Dy, x, p), otherwise Dy = grads(x, p).\nhessians_iip == true implies hessians!(H, x, p), otherwise H = hessians(x, p).\nfunc_and_grads_iip == true implies func_and_grads!(y, Dy, x, p),    otherwise y, Dy = func_and_grads(x, p).\nfunc_and_grads_and_hessians_iip == true implies   func_and_grads_and_hessians!(y, Dy, H, x, p),    else y, Dy, H = func_and_grads_and_hessians(x, p).\n\nAlternatively (or additionally), an AbstractAutoDiffBackend can be passed to  compute the derivatives if the relevant field isnothing.\n\n\n\n\n\n","category":"type"},{"location":"#Compromise.AlgorithmOptions","page":"Home","title":"Compromise.AlgorithmOptions","text":"AlgorithmOptions(; kwargs...)\n\nConfigure the optimization by passing keyword arguments:\n\nlog_level::Base.CoreLogging.LogLevel: Control verbosity by setting a min. level for @logmsg. Default: LogLevel(0)\nmax_iter::Int64: Maximum number of iterations. Default: 500\nstop_delta_min::Float64: Stop if the trust region radius is reduced to below stop_delta_min. Default: eps(Float64)\nstop_xtol_rel::Float64: Stop if the trial point xₜ is accepted and xₜ - x δx. Default: -Inf\nstop_xtol_abs::Float64: Stop if the trial point xₜ is accepted and xₜ - x ε. Default: -Inf\nstop_ftol_rel::Float64: Stop if the trial point xₜ is accepted and f(xₜ) - f(x) δf(x). Default: -Inf\nstop_ftol_abs::Float64: Stop if the trial point xₜ is accepted and f(xₜ) - f(x) ε. Default: -Inf\nstop_crit_tol_abs::Float64: Stop if for the approximate criticality it holds that χ(x) = ε and for the feasibility that θ = δ. Default: eps(Float64)\nstop_theta_tol_abs::Float64: Stop if for the approximate criticality it holds that χ(x) = ε and for the feasibility that θ = δ. Default: eps(Float64)\nstop_max_crit_loops::Int64: Stop after the criticality routine has looped stop_max_crit_loops times. Default: 1\neps_crit::Float64: Lower bound for criticality before entering Criticality Routine. Default: 0.1\neps_theta::Float64: Lower bound for feasibility before entering Criticality Routine. Default: 0.1\ncrit_B::Float64: At the end of the Criticality Routine the radius is possibly set to crit_B * χ. Default: 1000\ncrit_M::Float64: Criticality Routine runs until Δ ≤ crit_M * χ. Default: 3000\ncrit_alpha::Float64: Trust region shrinking factor in criticality loops. Default: 0.5\ndelta_init::Float64: Initial trust region radius. Default: 0.5\ndelta_max::Float64: Maximum trust region radius. Default: 2 ^ 5 * delta_init\ngamma_shrink_much::Float64: Most severe trust region reduction factor. Default: 0.1\ngamma_shrink::Float64: Trust region reduction factor. Default: 0.5\ngamma_grow::Float64: Trust region enlargement factor. Default: 2.0\nstrict_acceptance_test::Bool: Whether to require all objectives to be reduced or not. Default: true\nnu_accept::Float64: Acceptance threshold. Default: 0.01\nnu_success::Float64: Success threshold. Default: 0.9\nc_delta::Float64: Factor for normal step compatibility test. The smaller c_delta, the stricter the test. Default: 0.7\nc_mu::Float64: Factor for normal step compatibility test. The smaller c_mu, the stricter the test for small radii. Default: 100.0\nmu::Float64: Exponent for normal step compatibility test. The larger mu, the stricter the test for small radii. Default: 0.01\nkappa_theta::Float64: Factor in the model decrease condition. Default: 0.0001\npsi_theta::Float64: Exponent (for constraint violation) in the model decrease condition. Default: 2.0\nscaler_cfg::Symbol: Configuration to determine variable scaling (if model supports it). Either :box or :none. Default: :box\nstep_config::Any: Configuration object for descent and normal step computation. Default: SteepestDescentConfig()\nnl_opt::Symbol: NLopt algorithm symbol for restoration phase. Default: :LN_COBYLA\n\n\n\n\n\n","category":"type"},{"location":"#Compromise.MutableMOP","page":"Home","title":"Compromise.MutableMOP","text":"MutableMOP(; num_vars, kwargs...)\n\nInitialize a multi-objective problem with num_vars variables.\n\nFunctions\n\nThere can be exactly one (possibly vector-valued) objective function, one nonlinear equality constraint function, and one nonlinear inequality constraint function. For now, they have to be of type NonlinearFunction. You could provide these functions with the keyword-arguments objectives, nl_eq_constraints or nl_ineq_constraints or set the fields of the same name. To conveniently add user-provided functions, there are helper functions,  like add_objectives!.\n\nLinearConstraints\n\nBox constraints are defined by the vectors lb and ub. Linear equality constraints Ex=c are defined by the matrix E and the vector c. Inequality constraints read Axb and use A and b.\n\nSurrogate Configuration\n\nUse the keyword-arguments mcfg_objectives to provide an AbstractSurrogateModelConfig to define how the objectives should be modelled. By default, we assume ExactModelConfig(), which requires differentiable objectives.\n\n\n\n\n\n","category":"type"},{"location":"#Compromise.ValueArrays","page":"Home","title":"Compromise.ValueArrays","text":"A struct holding values computed for or derived from an AbstractMOP.\n\n\n\n\n\n","category":"type"},{"location":"#Compromise.add_function!","page":"Home","title":"Compromise.add_function!","text":"add_function!(func_field, mop, op, model_cfg; dim_out, backend=NoBackend())\n\nAdd the operator op to mop at func_field and use model configuration model_cfg. Keyword argument dim_out::Int is mandatory. E.g., add_function!(:objectives, mop, op, :rbf; dim_out=2) adds op as the bi-valued objective to mop.\n\n\n\n\n\n","category":"function"},{"location":"#Compromise.add_nl_eq_constraints!","page":"Home","title":"Compromise.add_nl_eq_constraints!","text":"add_nl_eq_constraints!(mop::MutableMOP, func, model_cfg=nothing; \n    dim_out::Int, kwargs...)\n\nSet function func to return the nonlinear equality constraints vector of mop. Argument model_cfg is optional and specifies the surrogate models for func. Can be nothing, a Symbol (:exact, :rbf, taylor1, taylor2), or an AbstractSurrogateModelConfig object.\n\nAll functions can be in-place, see keyword arguments func_iip.\n\nKeyword argument dim_out is mandatory and corresponds to the length of the result vector. The other kwargs... are passed to the inner AbstractNonlinearOperator as is. For options and defaults see NonlinearParametricFunction.\n\n\n\n\n\n","category":"function"},{"location":"#Compromise.add_nl_eq_constraints!-2","page":"Home","title":"Compromise.add_nl_eq_constraints!","text":"add_nl_eq_constraints!(mop::MutableMOP, func, grads, model_cfg=nothing; \n    dim_out::Int, kwargs...)\n\nSet function func to return the nonlinear equality constraints vector of mop. Argument model_cfg is optional and specifies the surrogate models for func. Can be nothing, a Symbol (:exact, :rbf, taylor1, taylor2), or an AbstractSurrogateModelConfig object. grads should be a function mapping a vector to the transposed jacobian of func.\n\nAll functions can be in-place, see keyword arguments func_iip and grads_iip.\n\nKeyword argument dim_out is mandatory and corresponds to the length of the result vector. The other kwargs... are passed to the inner AbstractNonlinearOperator as is. For options and defaults see NonlinearParametricFunction.\n\n\n\n\n\n","category":"function"},{"location":"#Compromise.add_nl_eq_constraints!-3","page":"Home","title":"Compromise.add_nl_eq_constraints!","text":"add_nl_eq_constraints!(mop::MutableMOP, func, grads, func_and_grads, model_cfg=nothing; \n    dim_out::Int, kwargs...)\n\nSet function func to return the nonlinear equality constraints vector of mop. Argument model_cfg is optional and specifies the surrogate models for func. Can be nothing, a Symbol (:exact, :rbf, taylor1, taylor2), or an AbstractSurrogateModelConfig object. grads should be a function mapping a vector to the transposed jacobian of func, while func_and_grads returns a primal vector and the gradients at the same time.\n\nAll functions can be in-place, see keyword arguments func_iip, grads_iip and  func_and_grads_iip.\n\nKeyword argument dim_out is mandatory and corresponds to the length of the result vector. The other kwargs... are passed to the inner AbstractNonlinearOperator as is. For options and defaults see NonlinearParametricFunction.\n\n\n\n\n\n","category":"function"},{"location":"#Compromise.add_nl_ineq_constraints!","page":"Home","title":"Compromise.add_nl_ineq_constraints!","text":"add_nl_ineq_constraints!(mop::MutableMOP, func, model_cfg=nothing; \n    dim_out::Int, kwargs...)\n\nSet function func to return the nonlinear inequality constraints vector of mop. Argument model_cfg is optional and specifies the surrogate models for func. Can be nothing, a Symbol (:exact, :rbf, taylor1, taylor2), or an AbstractSurrogateModelConfig object.\n\nAll functions can be in-place, see keyword arguments func_iip.\n\nKeyword argument dim_out is mandatory and corresponds to the length of the result vector. The other kwargs... are passed to the inner AbstractNonlinearOperator as is. For options and defaults see NonlinearParametricFunction.\n\n\n\n\n\n","category":"function"},{"location":"#Compromise.add_nl_ineq_constraints!-2","page":"Home","title":"Compromise.add_nl_ineq_constraints!","text":"add_nl_ineq_constraints!(mop::MutableMOP, func, grads, model_cfg=nothing; \n    dim_out::Int, kwargs...)\n\nSet function func to return the nonlinear inequality constraints vector of mop. Argument model_cfg is optional and specifies the surrogate models for func. Can be nothing, a Symbol (:exact, :rbf, taylor1, taylor2), or an AbstractSurrogateModelConfig object. grads should be a function mapping a vector to the transposed jacobian of func.\n\nAll functions can be in-place, see keyword arguments func_iip and grads_iip.\n\nKeyword argument dim_out is mandatory and corresponds to the length of the result vector. The other kwargs... are passed to the inner AbstractNonlinearOperator as is. For options and defaults see NonlinearParametricFunction.\n\n\n\n\n\n","category":"function"},{"location":"#Compromise.add_nl_ineq_constraints!-3","page":"Home","title":"Compromise.add_nl_ineq_constraints!","text":"add_nl_ineq_constraints!(mop::MutableMOP, func, grads, func_and_grads, model_cfg=nothing; \n    dim_out::Int, kwargs...)\n\nSet function func to return the nonlinear inequality constraints vector of mop. Argument model_cfg is optional and specifies the surrogate models for func. Can be nothing, a Symbol (:exact, :rbf, taylor1, taylor2), or an AbstractSurrogateModelConfig object. grads should be a function mapping a vector to the transposed jacobian of func, while func_and_grads returns a primal vector and the gradients at the same time.\n\nAll functions can be in-place, see keyword arguments func_iip, grads_iip and  func_and_grads_iip.\n\nKeyword argument dim_out is mandatory and corresponds to the length of the result vector. The other kwargs... are passed to the inner AbstractNonlinearOperator as is. For options and defaults see NonlinearParametricFunction.\n\n\n\n\n\n","category":"function"},{"location":"#Compromise.add_objectives!","page":"Home","title":"Compromise.add_objectives!","text":"add_objectives!(mop::MutableMOP, func, model_cfg=nothing; \n    dim_out::Int, kwargs...)\n\nSet function func to return the objectives vector of mop. Argument model_cfg is optional and specifies the surrogate models for func. Can be nothing, a Symbol (:exact, :rbf, taylor1, taylor2), or an AbstractSurrogateModelConfig object.\n\nAll functions can be in-place, see keyword arguments func_iip.\n\nKeyword argument dim_out is mandatory and corresponds to the length of the result vector. The other kwargs... are passed to the inner AbstractNonlinearOperator as is. For options and defaults see NonlinearParametricFunction.\n\n\n\n\n\n","category":"function"},{"location":"#Compromise.add_objectives!-2","page":"Home","title":"Compromise.add_objectives!","text":"add_objectives!(mop::MutableMOP, func, grads, model_cfg=nothing; \n    dim_out::Int, kwargs...)\n\nSet function func to return the objectives vector of mop. Argument model_cfg is optional and specifies the surrogate models for func. Can be nothing, a Symbol (:exact, :rbf, taylor1, taylor2), or an AbstractSurrogateModelConfig object. grads should be a function mapping a vector to the transposed jacobian of func.\n\nAll functions can be in-place, see keyword arguments func_iip and grads_iip.\n\nKeyword argument dim_out is mandatory and corresponds to the length of the result vector. The other kwargs... are passed to the inner AbstractNonlinearOperator as is. For options and defaults see NonlinearParametricFunction.\n\n\n\n\n\n","category":"function"},{"location":"#Compromise.add_objectives!-3","page":"Home","title":"Compromise.add_objectives!","text":"add_objectives!(mop::MutableMOP, func, grads, func_and_grads, model_cfg=nothing; \n    dim_out::Int, kwargs...)\n\nSet function func to return the objectives vector of mop. Argument model_cfg is optional and specifies the surrogate models for func. Can be nothing, a Symbol (:exact, :rbf, taylor1, taylor2), or an AbstractSurrogateModelConfig object. grads should be a function mapping a vector to the transposed jacobian of func, while func_and_grads returns a primal vector and the gradients at the same time.\n\nAll functions can be in-place, see keyword arguments func_iip, grads_iip and  func_and_grads_iip.\n\nKeyword argument dim_out is mandatory and corresponds to the length of the result vector. The other kwargs... are passed to the inner AbstractNonlinearOperator as is. For options and defaults see NonlinearParametricFunction.\n\n\n\n\n\n","category":"function"},{"location":"#Compromise.diff_mod!-Tuple{Any, Any, Any}","page":"Home","title":"Compromise.diff_mod!","text":"Evaluate the model gradients of mod at x and store results in mod_vals::SurrogateValueArrays.\n\n\n\n\n\n","category":"method"},{"location":"#Compromise.eval_and_diff_mod!-Tuple{Any, Any, Any}","page":"Home","title":"Compromise.eval_and_diff_mod!","text":"Evaluate and differentiate mod at x and store results in mod_vals::SurrogateValueArrays.\n\n\n\n\n\n","category":"method"},{"location":"#Compromise.eval_mod!-Tuple{Any, Any, Any}","page":"Home","title":"Compromise.eval_mod!","text":"Evaluate the models mod at x and store results in mod_vals::SurrogateValueArrays.\n\n\n\n\n\n","category":"method"},{"location":"#Compromise.lin_cons!-NTuple{4, Any}","page":"Home","title":"Compromise.lin_cons!","text":"lin_cons!(residual_vector, prod_cache, constraint_data, x)\n\nGiven a linear constraint A*x .<= b or A*x .== b, compute the product A*x and store  the result in prod_cache, and also compute A*x .- b and store the result in  residual_vector. constraint_data should either be the tuple (A,b)::Tuple{RMat,RVec} or nothing.\n\n\n\n\n\n","category":"method"},{"location":"#Compromise.scale!-Tuple{Any, Compromise.AbstractAffineScaler, Any}","page":"Home","title":"Compromise.scale!","text":"Scale ξ and set x according to x = T*ξ + t.\n\n\n\n\n\n","category":"method"},{"location":"#Compromise.scale_eq!-Tuple{Any, Compromise.AbstractAffineScaler, Any}","page":"Home","title":"Compromise.scale_eq!","text":"Make Aξ + b ? 0 applicable in scaled domain via A(inv(T)*x - inv(T)*t) + b ? 0.\n\n\n\n\n\n","category":"method"},{"location":"#Compromise.set_linear_constraints!-Tuple{Any, Any, Any, Any, Any, Symbol}","page":"Home","title":"Compromise.set_linear_constraints!","text":"set_linear_constraints!(opt, affine_vec, var_vec, mat, rhs, ctype)\n\nAdd linear (in-)equality constraints to JuMP model opt.\n\nIf ctype is :eq, then the constraints read affine_vec + mat * var_vec .== rhs.\nOtherwise, they read affine_vec + mat * var_vec .<= rhs.\n\nThis helper function returns a JuMP expression for the  matrix-vector-product mat*var_vec.\n\n\n\n\n\n","category":"method"},{"location":"#Compromise.unscale!-Tuple{Any, Compromise.AbstractAffineScaler, Any}","page":"Home","title":"Compromise.unscale!","text":"Unscale x and set ξ according to ξ = inv(T)*x - inv(T)*t.\n\n\n\n\n\n","category":"method"},{"location":"stopping/#Stopping-Criteria","page":"Stopping Criteria","title":"Stopping Criteria","text":"","category":"section"},{"location":"stopping/","page":"Stopping Criteria","title":"Stopping Criteria","text":"Currently, the stopping behavior is entirely determined by certain fields of the AlgorithmOptions object provided to optimize with the  keyword argument algo_opts.","category":"page"},{"location":"stopping/","page":"Stopping Criteria","title":"Stopping Criteria","text":"The relevant fields are ","category":"page"},{"location":"stopping/","page":"Stopping Criteria","title":"Stopping Criteria","text":"max_iter\nstop_delta_min, stop if the trust region radius is reduced to below stop_delta_min\nstop_xtol_rel, stop if the trial point xₜ is accepted and xₜ - x δx.\nstop_xtol_abs, stop if the trial point xₜ is accepted and xₜ - x ε.\nstop_ftol_rel, stop if the trial point xₜ is accepted and f(xₜ) - f(x) δf(x)\nstop_ftol_abs, stop if the trial point xₜ is accepted and f(xₜ) - f(x) ε.\nstop_crit_tol_abs, stop if for the approximate criticality it holds that χ(x) = ε and for the feasibility that θ = δ.\nstop_theta_tol_abs, stop if for the approximate criticality it holds that χ(x) = ε and for the feasibility that θ = δ.\nstop_max_crit_loops, stop after the criticality routine has looped stop_max_crit_loops times.","category":"page"},{"location":"stopping/","page":"Stopping Criteria","title":"Stopping Criteria","text":"All values can be provided as keyword arguments to the AlgorithmOptions constructor. For defaults, instantiate an object without arguments,","category":"page"},{"location":"stopping/","page":"Stopping Criteria","title":"Stopping Criteria","text":"algo_opts = AlgorithmOptions()\nalgo_opts.max_iter","category":"page"},{"location":"stopping/","page":"Stopping Criteria","title":"Stopping Criteria","text":"or take a look at the source code.","category":"page"},{"location":"stopping/#Internal","page":"Stopping Criteria","title":"Internal","text":"","category":"section"},{"location":"stopping/","page":"Stopping Criteria","title":"Stopping Criteria","text":"Internally, these options are converted to a tuple of AbstractStoppingCriterions. They implement the undocumented interface in src/stopping.jl. A stopping criterion can be checked at different positions in the loop, indicated by methods  check_pre_iteration, check_post_descent_step, check_post_iteration, check_pre_crit_loop and check_post_crit_loop. At the relevant position, the corresponding method","category":"page"},{"location":"stopping/","page":"Stopping Criteria","title":"Stopping Criteria","text":"function evaluate_stopping_criterion(\n    crit::AbstractStoppingCriterion,\n    Δ, mop, mod, scaler, lin_cons, scaled_cons,\n    vals, vals_tmp, step_vals, mod_vals, filter, iter_meta, step_cache, algo_opts,\n)\n    return nothing\nend","category":"page"},{"location":"stopping/","page":"Stopping Criteria","title":"Stopping Criteria","text":"is called. If it returns something other than nothing, then the algorithm stops. iter_meta already stores radius information, but not for the criticality loop.  That is why it can be provided as its own argument Δ (at least for now). The contents of the arguments differ depending on the position of evaluation within the optimization loop.","category":"page"},{"location":"stopping/#User-Callbacks","page":"Stopping Criteria","title":"User Callbacks","text":"","category":"section"},{"location":"stopping/","page":"Stopping Criteria","title":"Stopping Criteria","text":"You can implement the same interface for your own callback to gather information and also stop the algorithm based on your  own criteria.","category":"page"},{"location":"stopping/","page":"Stopping Criteria","title":"Stopping Criteria","text":"Base.@kwdef struct MyGatheringCallback  <: Compromise.AbstractStoppingCriterion \n    iterates :: Matrix{Float64} = Matrix{Float64}(undef, 2, 2) \n    it_counter :: Base.RefValue{Int} = Ref(0)\nend\nCompromise.check_pre_iteration(::MyGatheringCallback)=true\n        \nfunction Compromise.evaluate_stopping_criterion(\n    crit::MyGatheringCallback,\n    Δ, mop, mod, scaler, lin_cons, scaled_cons,\n    vals, vals_tmp, step_vals, mod_vals, filter, iter_meta, step_cache, algo_opts,\n)\n    i = crit.it_counter[] += 1\n    i > 2 && return crit\n    crit.iterates[:,i] .= vals.x\n    return nothing\nend\n\nmop = MutableMOP(;num_vars=2)\nadd_objectives!(\n    mop, x -> [sum((x.-1).^2), sum((x.+1).^2)], :rbf; \n    dim_out=2, func_iip=false,\n)\nfinal_vals, stop_code = optimize(mop, rand(2); user_callback=MyGatheringCallback())","category":"page"}]
}
