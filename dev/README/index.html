<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>README · Compromise.jl</title><meta name="title" content="README · Compromise.jl"/><meta property="og:title" content="README · Compromise.jl"/><meta property="twitter:title" content="README · Compromise.jl"/><meta name="description" content="Documentation for Compromise.jl."/><meta property="og:description" content="Documentation for Compromise.jl."/><meta property="twitter:description" content="Documentation for Compromise.jl."/><meta property="og:url" content="https://manuelbb-upb.github.io/Compromise.jl/README/"/><meta property="twitter:url" content="https://manuelbb-upb.github.io/Compromise.jl/README/"/><link rel="canonical" href="https://manuelbb-upb.github.io/Compromise.jl/README/"/><script data-outdated-warner src="../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../assets/documenter.js"></script><script src="../search_index.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-mocha.css" data-theme-name="catppuccin-mocha"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-macchiato.css" data-theme-name="catppuccin-macchiato"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-frappe.css" data-theme-name="catppuccin-frappe"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-latte.css" data-theme-name="catppuccin-latte"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit"><a href="../">Compromise.jl</a></span></div><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li><a class="tocitem" href="../">Home</a></li><li><span class="tocitem">Tutorials</span><ul><li class="is-active"><a class="tocitem" href>README</a><ul class="internal"><li><a class="tocitem" href="#About-“CoMPrOMISE”"><span>About “CoMPrOMISE”</span></a></li><li><a class="tocitem" href="#Example"><span>Example</span></a></li></ul></li></ul></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">Tutorials</a></li><li class="is-active"><a href>README</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>README</a></li></ul></nav><div class="docs-right"><a class="docs-navbar-link" href="https://github.com/manuelbb-upb/Compromise.jl/blob/main/docs/literate_src/README.jl#" title="Edit source on GitHub"><span class="docs-icon fa-solid"></span></a><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><h1 id="Compromise.jl"><a class="docs-heading-anchor" href="#Compromise.jl">Compromise.jl</a><a id="Compromise.jl-1"></a><a class="docs-heading-anchor-permalink" href="#Compromise.jl" title="Permalink"></a></h1><p><a href="https://manuelbb-upb.github.io/Compromise.jl/stable/"><img src="https://img.shields.io/badge/docs-stable-blue.svg" alt="Stable"/></a> <a href="https://manuelbb-upb.github.io/Compromise.jl/dev/"><img src="https://img.shields.io/badge/docs-dev-blue.svg" alt="Dev"/></a></p><h2 id="About-“CoMPrOMISE”"><a class="docs-heading-anchor" href="#About-“CoMPrOMISE”">About “CoMPrOMISE”</a><a id="About-“CoMPrOMISE”-1"></a><a class="docs-heading-anchor-permalink" href="#About-“CoMPrOMISE”" title="Permalink"></a></h2><p><strong>Co</strong>nstrained <strong>M</strong>ultiobjective <strong>Pr</strong>oblem <strong>O</strong>ptimizer with <strong>M</strong>odel <strong>I</strong>nformation to <strong>S</strong>ave <strong>E</strong>valuations</p><p>This package provides a flexible first-order solver for constrained and unconstrained nonlinear multi-objective problems. It uses a trust region approach and either exact derivatives or local surrogate models for a derivative-free descent. Box constraints are respected during model construction and treated as unrelaxable. Box constraints and linear constraints are supported and passed down to an inner LP solver. Nonlinear constraint functions can be modelled and are dealt with by incorporating a filter. They are <em>relaxable</em>, i.e., all other functions must be computable even when the constraints are violated.</p><h3 id="Release-Notes"><a class="docs-heading-anchor" href="#Release-Notes">Release Notes</a><a id="Release-Notes-1"></a><a class="docs-heading-anchor-permalink" href="#Release-Notes" title="Permalink"></a></h3><p>I don&#39;t really keep up a consistent versioning scheme. But the changes in this section have been significant enough to warrant some comments.</p><h4 id="Version-0.3"><a class="docs-heading-anchor" href="#Version-0.3">Version 0.3</a><a id="Version-0.3-1"></a><a class="docs-heading-anchor-permalink" href="#Version-0.3" title="Permalink"></a></h4><p>I did not exactly keep track of all the changes, but some types and default settings have changed, so a new breaking version is warranted. We have set-based algorithms now, but they are drafts only and mostly undocumented. Originally, it was <code>optimize_set</code>, but I tested <code>optimize_many</code> the most. Try <code>optimize_many</code> at your own risk.</p><h4 id="Version-0.2.0"><a class="docs-heading-anchor" href="#Version-0.2.0">Version 0.2.0</a><a id="Version-0.2.0-1"></a><a class="docs-heading-anchor-permalink" href="#Version-0.2.0" title="Permalink"></a></h4><p>This was an intermediate version that has been superseded fast.</p><h4 id="Version-0.2.0-2"><a class="docs-heading-anchor" href="#Version-0.2.0-2">Version 0.2.0</a><a class="docs-heading-anchor-permalink" href="#Version-0.2.0-2" title="Permalink"></a></h4><ul><li>We import and re-export <code>@set</code> and <code>@reset</code> from Accessors.jl.</li><li><code>AlgorithmOptions</code> is no immutable and type-stable. <code>@set algo_opts.float_type</code> will trigger cnoversion and setting of type-dependent defaults.</li><li>Likewise, <code>RBFConfig</code> is no longer mutable and has concrete types.</li><li><code>TypedMOP</code> supports <code>@set</code> and <code>@reset</code> for <code>objectives</code>, <code>nl_eq_constraints</code> and <code>nl_eq_constraints</code>.</li><li>The <code>AbstractNonlinearOperator</code> interface now requires <code>CompromiseEvaluators.operator_dim_in</code> and <code>CompromiseEvaluators.operator_dim_out</code>.</li><li>The <code>ReturnObject</code> now references the whole cache (basically a NamedTuple of internal structs.)</li><li><code>SimpleMOP</code> reset call counters by default.</li></ul><h4 id="Version-0.1.0"><a class="docs-heading-anchor" href="#Version-0.1.0">Version 0.1.0</a><a id="Version-0.1.0-1"></a><a class="docs-heading-anchor-permalink" href="#Version-0.1.0" title="Permalink"></a></h4><p>This release is breaking, because the RBF database is no longer thread-safe by default. Instead, <code>ConcurrentUtils</code> is a weak dependency and no longer mandatory. To use a thread-safe RBF database, either configure your problem functions with <code>:rbfLocked</code>, use an <code>RBFConfig</code> with <code>database_rwlock = ConcurrentRWLock()</code> or pre-initialize a thread-safe database by setting the field <code>rwlock</code>.</p><h4 id="Version-0.0.3"><a class="docs-heading-anchor" href="#Version-0.0.3">Version 0.0.3</a><a id="Version-0.0.3-1"></a><a class="docs-heading-anchor-permalink" href="#Version-0.0.3" title="Permalink"></a></h4><p>Internally, there have been major changes regarding the caching of MOP and surrogate result values. Previously, separate preallocation functions were required (e.g., <code>prealloc_fx</code> …). Now, there is only <code>init_value_caches</code>, and instead of accessing the cache arrays as properties, there are dedicated getter methods.</p><h4 id="Version-0.0.2"><a class="docs-heading-anchor" href="#Version-0.0.2">Version 0.0.2</a><a id="Version-0.0.2-1"></a><a class="docs-heading-anchor-permalink" href="#Version-0.0.2" title="Permalink"></a></h4><h5 id="RBF-Surrogate-Models"><a class="docs-heading-anchor" href="#RBF-Surrogate-Models">RBF Surrogate Models</a><a id="RBF-Surrogate-Models-1"></a><a class="docs-heading-anchor-permalink" href="#RBF-Surrogate-Models" title="Permalink"></a></h5><p>The internals of how RBF Surrogates are constructed has been redone. As before, the construction is based off “Derivative-Free Optimization Algorithms For Computationally Expensive Functions,” (Wild, 2009). In the old version, I did not really care for the matrix factorizations. Finding a poised set of points for fully-linear interpolation needs repeated QR factorizations of the point matrix. Afterwards, additional points are found by updating the Cholesky factorization of some symmetric matrix product involving the RBF Gram matrix.</p><ul><li>To save allocations, the QR factorizations now make use of structures similar to</li></ul><p>those in <code>FastLapackInterface</code>.   Once I manage to <a href="https://github.com/DynareJulia/FastLapackInterface.jl/issues/40">make a pull request</a>   to avoid even more allocations, we can also make <code>FastLapackInterface</code> a dependency.</p><ul><li>The Cholesky factorization is now updated by using the formulas from the reference, and the factors are used to compute the surrogate coefficients.</li><li>In both cases, buffers are pre-allocated to support a maximum number of interpolation points, and we work with views mainly. Such temporary buffers are stored in <code>RBFTrainingBuffers</code>.</li><li>An <code>RBFModel</code> now only needs <code>RBFParameters</code> for successful training and reproducible evaluation. Most importantly, evaluation is decoupled from the <code>RBFDatabase</code>!! In older versions, we would view into the database to query interpolation points. These are now copied instead, so that changes to the database don&#39;t invalidate a model.</li><li>With <a href="https://github.com/manuelbb-upb/Compromise.jl/commit/cc709fa0391d4a796b543a0733c31fb6f2e6ad46">commit cc709fa</a> we can thus share a database in multiple optimization runs.</li><li>As an aside, there is a whole new backend for RBFs, which can be used in a standalone manner, too.</li></ul><p>For most of the RBF related changes, <a href="https://github.com/manuelbb-upb/Compromise.jl/commit/ab5cba8f3d4ba39cd4bf2757a072bb655b4f0cc2">commit ab5cba8</a> is most relevant.</p><h5 id="Other-changes"><a class="docs-heading-anchor" href="#Other-changes">Other changes</a><a id="Other-changes-1"></a><a class="docs-heading-anchor-permalink" href="#Other-changes" title="Permalink"></a></h5><ul><li>There likely was a bug in how descent directions were computed. In old versions, I tried to avoid the computation of an initial steplength by making it part of the descent direction sub-problem, but accounting for the change in criticality measure did not work out well. <a href="https://github.com/manuelbb-upb/Compromise.jl/commit/f1386c29e19b7d5c3bad28fc03af8024015666c5">Commit f1386c2</a> makes things look a bit more elegant.</li><li>At some point in time, I messed up affine scaling. Should work now, and there is tests for it.</li><li>Threaded parallel execution is now supported internally (but improvised).</li><li>Lots of tests.</li><li>Changes to <code>AbstractNonlinearOperator</code> interface. A new <code>AbstractNonlinearOperatorWrapper &lt;: AbstractNonlinearOperator</code>.</li><li>New defaults in <code>AlgorithmOptions</code>. Stopping based mainly on minimum radius.</li><li>A new return type (<code>ReturnObject</code>).</li></ul><h2 id="Example"><a class="docs-heading-anchor" href="#Example">Example</a><a id="Example-1"></a><a class="docs-heading-anchor-permalink" href="#Example" title="Permalink"></a></h2><h3 id="Constrained-Two-Parabolas-Problem"><a class="docs-heading-anchor" href="#Constrained-Two-Parabolas-Problem">Constrained Two-Parabolas Problem</a><a id="Constrained-Two-Parabolas-Problem-1"></a><a class="docs-heading-anchor-permalink" href="#Constrained-Two-Parabolas-Problem" title="Permalink"></a></h3><p>This first example uses Taylor Polynomials to approximate the function locally. For that we need a gradient function. But we also show, how to add functions with derivative-free surrogates – in this case nonlinear constraints.</p><p>First we load the optimizer package, “Compromise.jl”:</p><pre><code class="language-julia hljs">using Compromise</code></pre><p>The package exports a simple problem structure, <code>MutableMOP</code>. As the name suggests, this is a mutable structure to define a multi-objective optimization problem. We can use it to set up a problem step by step. The only information required for initialization is the number of variables:</p><pre><code class="language-julia hljs">mop = MutableMOP(;num_vars = 2)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">MutableMOP
  objectives: Nothing nothing
  nl_eq_constraints: Nothing nothing
  nl_ineq_constraints: Nothing nothing
  reset_call_counters: Bool true
  num_vars: Int64 2
  x0: Nothing nothing
  mcfg_objectives: ExactModelConfig ExactModelConfig()
  mcfg_nl_eq_constraints: ExactModelConfig ExactModelConfig()
  mcfg_nl_ineq_constraints: ExactModelConfig ExactModelConfig()
  lb: Nothing nothing
  ub: Nothing nothing
  E: Nothing nothing
  c: Nothing nothing
  A: Nothing nothing
  b: Nothing nothing
</code></pre><p>For a <code>MutableMOP</code>, all functions are vector-to-vector. We can define the objectives (<code>objectives</code>), nonlinear inequality constraints (<code>nl_ineq_constraints</code>) and nonlinear equality constraints (<code>nl_eq_constraints</code>). By default, these fields default to <code>nothing</code>. Alternatively, they need objects of type <code>Compromise.NonlinearFunction</code>. We have helpers to support normal Julia functions. For example, consider this vector-to-vector function:</p><pre><code class="language-julia hljs">function objective_function(x)
    return [
        (x[1] - 2)^2 + (x[2] - 1)^2;
        (x[1] - 2)^2 + (x[2] + 1)^2
    ]
end</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">objective_function (generic function with 1 method)</code></pre><p>We can easily derive the gradients, so let&#39;s also define them manually, to use derivative-based models:</p><pre><code class="language-julia hljs">function objective_grads(x)
    # return the transposed Jacobian, i.e., gradients as columns
    df11 = df21 = 2 * (x[1] - 2)
    df12 = 2 * (x[2] - 1)
    df22 = 2 * (x[2] + 1)
    return [ df11 df21; df12 df22 ]
end</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">objective_grads (generic function with 1 method)</code></pre><p>To add these functions to <code>mop</code>, we call the helper method <code>add_objectives</code> and also specify the model class to be used. There are shorthand symbols, for example <code>:exact</code> or <code>taylor1</code>, for objectives with known gradients. We also have to tell the optimizer about the function signature. <code>func_iip=true</code> would imply an in-place objective with signature <code>objective_function!(fx, x)</code>. <code>dim_out</code> is a mandatory argument.</p><pre><code class="language-julia hljs">add_objectives!(
    mop, objective_function, objective_grads, :taylor1;
    dim_out=2, func_iip=false, grads_iip=false
)</code></pre><div class="admonition is-info"><header class="admonition-header">Note</header><div class="admonition-body"><p>For the above objective function, it would be sensible to additionally have a function <code>objective_values_and_grads</code>, that returns the objectives and gradients at the same time. That is possible, <code>MutableMOP</code> has an interface for such optimizations.</p></div></div><p>We support non-convex, nonlinear constraints (as long as they are relaxable). For example, we can constrain the problem to ℝ² without unit ball. For demonstration purposes, use an in-place function:</p><pre><code class="language-julia hljs">nl_ineq_function!(y, x) = y[1] = 1 - sum(x.^2)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">nl_ineq_function! (generic function with 1 method)</code></pre><p>Of course, that is a fairly simple constraint function. If it was more complicated, we could be tempted to use automatic differentiation for derivative calculations. Instead, you can also use derivative-free models, such as radial basis function (RBF) models.</p><p>For now, we stick with the fixed shape parameter and finalize our problem:</p><pre><code class="language-julia hljs">add_nl_ineq_constraints!(mop, nl_ineq_function!, :rbf;
    func_iip=true, dim_out=1
)</code></pre><p>The <code>MutableMOP</code> is turned into a <code>TypedMOP</code> during initialization. We can thus simply pass it to <code>optimize</code>:</p><pre><code class="language-julia hljs">ret = optimize(mop, [-2.0, 0.5])</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">ReturnObject
x0   = [-2.00e+00, 5.00e-01]
x*   = [2.00e+00, 9.92e-01]
f(x*)= [7.06e-05, 3.97e+00]
code = MinimumRadiusStopping(2.220446049250313e-16)</code></pre><p><code>ret</code> is the return object. You can query it using functions like <code>opt_vars</code> etc. Final argument vector:</p><pre><code class="language-julia hljs">opt_vars(ret)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">2-element Vector{Float64}:
 1.9999999203478478
 0.9915961870532211</code></pre><p>Final value vector:</p><pre><code class="language-julia hljs">opt_objectives(ret)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">2-element Vector{Float64}:
 7.062407205079386e-5
 3.9664553722849347</code></pre><p>Final constraint vector:</p><pre><code class="language-julia hljs">opt_nl_ineq_constraints(ret)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">1-element Vector{Float64}:
 -3.983262679569884</code></pre><h3 id="More-RBF-Options"><a class="docs-heading-anchor" href="#More-RBF-Options">More RBF Options</a><a id="More-RBF-Options-1"></a><a class="docs-heading-anchor-permalink" href="#More-RBF-Options" title="Permalink"></a></h3><p>Instead of passing <code>:rbf</code>, you can also pass an <code>RBFConfig</code>. To use the Gaussian kernel:</p><pre><code class="language-julia hljs">cfg = RBFConfig(; kernel=GaussianKernel())</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">RBFConfig{Float64, GaussianKernel{Int64}, Nothing, Nothing, Nothing}
  kernel: GaussianKernel{Int64}
  poly_deg: Int64 1
  shape_parameter_function: Nothing nothing
  max_points: Nothing nothing
  database: Nothing nothing
  database_rwlock: Nothing nothing
  database_size: Nothing nothing
  database_chunk_size: Nothing nothing
  enforce_fully_linear: Bool true
  search_factor: Float64 2.000001
  sampling_factor: Float64 1.0
  max_search_factor: Float64 2.000001
  max_sampling_factor: Float64 1.0
  th_qr: Float64 0.2499998750000625
  th_cholesky: Float64 1.0e-9
</code></pre><p>Or the inverse multiquadric:</p><pre><code class="language-julia hljs">cfg = RBFConfig(; kernel=InverseMultiQuadricKernel())</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">RBFConfig{Float64, InverseMultiQuadricKernel{Int64}, Nothing, Nothing, Nothing}
  kernel: InverseMultiQuadricKernel{Int64}
  poly_deg: Int64 1
  shape_parameter_function: Nothing nothing
  max_points: Nothing nothing
  database: Nothing nothing
  database_rwlock: Nothing nothing
  database_size: Nothing nothing
  database_chunk_size: Nothing nothing
  enforce_fully_linear: Bool true
  search_factor: Float64 2.000001
  sampling_factor: Float64 1.0
  max_search_factor: Float64 2.000001
  max_sampling_factor: Float64 1.0
  th_qr: Float64 0.2499998750000625
  th_cholesky: Float64 1.0e-9
</code></pre><p>Then:</p><pre><code class="language-julia hljs">mop = MutableMOP(; num_vars=2)
add_objectives!(
    mop, objective_function, cfg; dim_out=2, func_iip=false,
)
ret = optimize(mop, [-2.0, 0.5])</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">ReturnObject
x0   = [-2.00e+00, 5.00e-01]
x*   = [2.00e+00, 5.00e-01]
f(x*)= [2.50e-01, 2.25e+00]
code = MinimumRadiusStopping(2.220446049250313e-16)</code></pre><p>See the docstring for more options.</p><h4 id="Sharing-an-RBFDatabase"><a class="docs-heading-anchor" href="#Sharing-an-RBFDatabase">Sharing an <code>RBFDatabase</code></a><a id="Sharing-an-RBFDatabase-1"></a><a class="docs-heading-anchor-permalink" href="#Sharing-an-RBFDatabase" title="Permalink"></a></h4><p>Normally, each optimization run initializes a new database. But a database is only ever referenced. We can thus pre-initialize a database and use it in multiple runs:</p><pre><code class="language-julia hljs">rbf_db = Compromise.RBFModels.init_rbf_database(2, 2, nothing, nothing, Float64)
cfg = RBFConfig(; database=rbf_db)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">RBFConfig{Float64, CubicKernel{Int64}, Compromise.RBFModels.RBFDatabase{Float64, Compromise.PseudoRWLock}, Nothing, Nothing}
  kernel: CubicKernel{Int64}
  poly_deg: Int64 1
  shape_parameter_function: Nothing nothing
  max_points: Nothing nothing
  database: Compromise.RBFModels.RBFDatabase{Float64, Compromise.PseudoRWLock}
  database_rwlock: Nothing nothing
  database_size: Nothing nothing
  database_chunk_size: Nothing nothing
  enforce_fully_linear: Bool true
  search_factor: Float64 2.000001
  sampling_factor: Float64 1.0
  max_search_factor: Float64 2.000001
  max_sampling_factor: Float64 1.0
  th_qr: Float64 0.2499998750000625
  th_cholesky: Float64 1.0e-9
</code></pre><p>Set up problem:</p><pre><code class="language-julia hljs">mop = MutableMOP(; num_vars=2)
objf_counter = Ref(0)
function counted_objf(x)
    global objf_counter[] += 1
    return objective_function(x)
end
add_objectives!(
    mop, counted_objf, cfg; dim_out=2, func_iip=false,
)</code></pre><p>First run:</p><pre><code class="language-julia hljs">ret = optimize(mop, [-2.0, 0.5])
objf_counter[]</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">76</code></pre><p>Second run:</p><pre><code class="language-julia hljs">ret = optimize(mop, [-2.0, 0.0])
objf_counter[]</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">141</code></pre><h5 id="Parallelism"><a class="docs-heading-anchor" href="#Parallelism">Parallelism</a><a id="Parallelism-1"></a><a class="docs-heading-anchor-permalink" href="#Parallelism" title="Permalink"></a></h5><p>The RBF update algorithm has a lock to access the database in a safe way (?) when multiple optimization runs are done concurrently. There even is an “algorithm” for this:</p><pre><code class="language- hljs">using ConcurrentUtils
mop = MutableMOP(; num_vars=2)
add_objectives!(
    mop, counted_objf, :rbfLocked; dim_out=2, func_iip=false,
)
X0 = [
    -2.0    -2.0    0.0
    0.5     0.0     0.0
]
opts = Compromise.ThreadedOuterAlgorithmOptions(;
    inner_opts=AlgorithmOptions(;
        stop_delta_min = 1e-8,
    )
)
rets = Compromise.optimize_with_algo(mop, opts, X0)</code></pre><h3 id="Stopping-based-on-Number-of-Function-Evaluations"><a class="docs-heading-anchor" href="#Stopping-based-on-Number-of-Function-Evaluations">Stopping based on Number of Function Evaluations</a><a id="Stopping-based-on-Number-of-Function-Evaluations-1"></a><a class="docs-heading-anchor-permalink" href="#Stopping-based-on-Number-of-Function-Evaluations" title="Permalink"></a></h3><p>The restriction of evaluation budget is a property of the evaluators. Because of this, it is not configurable with <code>AlgorithmOptions</code>. You can pass <code>max_func_calls</code> as a keyword argument to <code>add_objectives!</code> and similar functions. Likewise, <code>max_grad_calls</code> restricts the number of gradient calls, <code>max_hess_calls</code> limits Hessian computations.</p><p>~~For historic reasons, the count is kept between runs.~~ The count is now reset between runs by default. To reset the count between runs (sequential or parallel), indicate it when setting up the MOP.</p><pre><code class="language-julia hljs">mop = MutableMOP(; num_vars=2, reset_call_counters=false)   # default
add_objectives!(
    mop, objective_function, :rbf; dim_out=2, func_iip=false, max_func_calls=10
)
ret1 = optimize(mop, [-2, .5])</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">ReturnObject
x0   = [-2.00e+00, 5.00e-01]
x*   = [-1.74e-03, 5.00e-01]
f(x*)= [4.26e+00, 6.26e+00]
code = Compromise.CompromiseEvaluators.BudgetExhausted(10, 10, 0)</code></pre><p>Now, there is no budget left for a second run:</p><pre><code class="language-julia hljs">ret2 = optimize(mop, [-2, -.5])
ismissing(opt_vars(ret2))</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">true</code></pre><p>Here is a remedy:</p><pre><code class="language-julia hljs">mop.reset_call_counters=true
ret1 = optimize(mop, [-2, .5])</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">ReturnObject
x0   = [-2.00e+00, 5.00e-01]
x*   = [-1.74e-03, 5.00e-01]
f(x*)= [4.26e+00, 6.26e+00]
code = Compromise.CompromiseEvaluators.BudgetExhausted(10, 10, 0)</code></pre><p>Now, there <strong>is</strong> budget left for a second run:</p><pre><code class="language-julia hljs">ret2 = optimize(mop, [-2, -.5])
!ismissing(opt_vars(ret2))</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">true</code></pre><h3 id="Automatic-Differentiation"><a class="docs-heading-anchor" href="#Automatic-Differentiation">Automatic Differentiation</a><a id="Automatic-Differentiation-1"></a><a class="docs-heading-anchor-permalink" href="#Automatic-Differentiation" title="Permalink"></a></h3><p>There is an optional <code>ForwardDiff</code> extension. To use a derivative-based model without specifying the gradients by-hand, first load <code>ForwardDiff</code>.</p><pre><code class="language-julia hljs">using ForwardDiff</code></pre><p>Now, <code>ForwardDiffBackend</code> should be available:</p><pre><code class="language-julia hljs">diff_backend = ForwardDiffBackend()</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">ForwardDiffBackendExt.ForwardDiffBackend()</code></pre><p>Set up the problem:</p><pre><code class="language-julia hljs">mop = MutableMOP(2)
add_objectives!(mop, objective_function, :exact;
    func_iip=false, dim_out=2, backend=diff_backend
)

optimize(mop, -5 .+ 10 .* rand(2))</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">ReturnObject
x0   = [-2.15e+00, -3.99e+00]
x*   = [-1.15e+00, -3.99e+00]
f(x*)= [3.48e+01, 1.89e+01]
code = MinimumRadiusStopping(2.220446049250313e-16)</code></pre><hr/><p><em>This page was generated using <a href="https://github.com/fredrikekre/Literate.jl">Literate.jl</a>.</em></p></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../">« Home</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="auto">Automatic (OS)</option><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option><option value="catppuccin-latte">catppuccin-latte</option><option value="catppuccin-frappe">catppuccin-frappe</option><option value="catppuccin-macchiato">catppuccin-macchiato</option><option value="catppuccin-mocha">catppuccin-mocha</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.7.0 on <span class="colophon-date" title="Tuesday 24 September 2024 14:37">Tuesday 24 September 2024</span>. Using Julia version 1.9.4.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
